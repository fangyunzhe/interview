## 1. Java 语言相关

#### 1.1. String 为什么设计成 final 的？

#### 1.2. 简述 Java 的异常处理机制.

在 Java 中有两种异常处理方式：抛出异常和捕获异常

**抛出异常**

抛出异常可分为显式和隐式两种。显式抛异常的主体是应用程序，它指的是在程序中使用 **throw** 关键字，手动将异常抛出。

隐式抛异常的主体是 Java 虚拟机，它指的是 Java 虚拟机在执行过程中，碰到无法继续执行的异常状态，自动抛出异常。比如在执行读取数组操作时，发现输入的索引值时负数，孤儿抛出数组越界异常（ArrayindexOutOfBoundsException）。

**捕获异常**

捕获异常则涉及三种代码块：

1. try 代码块：用来标记需要进行异常监控的代码

2. catch 代码块：用来捕获在 try 块中出发的某种执行类型的异常。在 Java 中，try 代码块后面可以跟着多个 catch 代码块，来捕获不同的异常，Java 虚拟机会从上至下进行异常匹配来进行处理，因此前面的 catch 代码块所捕获的异常类型不能覆盖后面的，否则编译器会报错。

3. finnally 代码块：跟在 try 代码块和 catch 代码块之后，用来声明一段必定执行的代码。它的设计初衷是为了避免跳过某些关键的清理代码，例如关闭已打开的系统资源。

   在程序正常执行的情况下，finally 代码块会在 try 代码块之后执行，如果 try 代码块出发异常并且没有被捕获，finally 代码块会直接运行并且在运行之后抛出该异常。

   如果异常被 catch 代码块捕获，finally 代码块则在 catch 代码块之后运行。在某些情况下 catch代码块也触发了异常，finally代码块同样会运行，并会抛出 catch 代码块处罚的异常。在极端情况下，finally 代码块也触发了异常，则会中断当前 finally 块的代码并抛出异常。

**异常的基本概念**

在Java 语言规范中，所有异常都是 Throwable 类或者其子嘞的实例。Throwable 有两大直接子类，第一个是 Error，涵盖程序不应捕获的异常，当触发 Error 时，它的执行状态已经无法恢复，需要终止线程甚至终止虚拟机。第二子类是 Exception，涵盖程序可能需要捕获并且处理的异常。

Exception 包含检查异常和非检查异常，对于检查异常，需要在程序中显式地捕获，或者在方法中用 throws 关键字标注。

#### 1.3. 为什么实现 equals() 必须先实现 hashCode() 方法？

1. 如果两个对象相同则 hashCode 一定相等；但是 hashCode 相等时，两个对象却不一定相同
2. 为了提高程序的执行效率才实现了 hashCode 方法，先进行 hashCode 比较，如果不同就没有必要进行 equals 比较了，这样大大减少了 equals 的使用次数，从而提高程序的执行效率。

所以如果只重写 equals() 不重写 hashCode（）方法可能会出现问题

**重写 equals() 方法注意事项**

- 自反性：对于任意不为 null 的引用值 x，x.equals(x) 一定是true，自己和自己比较一定返回 true
- 对称性：对于任意不为`null`的引用值`x`和`y`，当且仅当`x.equals(y)`是`true`时，`y.equals(x)`也是`true`。
- 传递性：对于任意不为`null`的引用值`x`、`y`和`z`，如果`x.equals(y)`是`true`，同时`y.equals(z)`是`true`，那么`x.equals(z)`一定是`true`。
- 一致性：对于任意不为`null`的引用值`x`和`y`，如果用于equals比较的对象信息没有被修改的话，多次调用时`x.equals(y)`要么一致地返回`true`要么一致地返回`false`。
- 对于任意不为`null`的引用值`x`，`x.equals(null)`返回`false`。

**重写 hashCode() 方法注意事项**

- 在一个 Java 应用执行期间，如果一个对象提供给 equals 做比较的信息没有被修改的话，该对象多次调用`hashCode()`方法，该方法必须始终如一返回同一个整型数值。
- 如果两个对象根据`equals()`方法是相等的，那么调用二者各自的`hashCode()`方法必须返回相同结果
- 并不要求根据`equals(java.lang.Object)`方法不相等的两个对象，调用各自的`hashCode()`方法必须产生不同结果。

#### 1.4. String name = new String("abc") 创建了几个对象？

```java
String str1 = "abc"; // 在常量池中
String str2 = new String("abc"); // 在堆上
```

![img](https://mdimg.wxwenku.com/getimg/ccdf080c7af7e8a10e9b88444af9839324e8c9704bd82b2a25cdb66d806fa9919a0d6ab2346eec55b6e29a91ba0819e0.jpg)

当直接赋值时，字符串 "abc" 会被存储在常量池中，只有一份，此时赋值操作等于是创建 0 个或 1 个对象，取决于常量池中是否已经存在字符串 "abc"。

通过 String s = new String("abc") 方式创建字符串对象时，在编译期间，会将等号右边的 "abc" 常量放在常量池中，在程序运行时，先在堆中创建一个 String 对象，该对象的内容指向常量池的 "abc" 项。然后将s变量压栈，栈中s变量指向堆中的String对象。

所以答案是 1 个或者 2 个，取决于常量池中是否存在字符串 "abc"。

#### 1.5. 创建对象有几种方式？

**使用 new 关键字**

是最常见也是最简单的一种创建对象的方式

```java
Object obj = new Object();
```

**使用反射**

使用 Class 类的 newInstance() 方法创建对象，调用无参构造函数创建对象。1.9 以后已过时。

```java
Object obj = Object.class.newInstance();
```

使用 Constructor 类的 newInstance() 方法，可以调用有参数的和私有的构造函数。

```java
Object obj = Object.class.getConstructor().newInstance();
```

**使用 clone**

对于实现 Cloneable 接口的对象可以调用 clone() 方法克隆一个新的对象。

clone() 方法是浅拷贝的，也就是说在拷贝时如果成员变量是引用类型的话成员变量是不会进行拷贝的。如果需要实现深拷贝，需要覆盖 clone() 方法，同时将成员变量也进行克隆，如果成员变量还引用了其它对象，被引用的对象也需要进行单独拷贝。所以实现深拷贝是比较麻烦的，尤其是在引用第三方对象的时候，由于第三方对象没有实现 clone() 方法，是不能进行深拷贝的。

**反序列化**

序列化和反序列化主要用于对象的持久化和远程传输，一个对象要想进行序列化和反序列化，需要实现 Serializable 接口。

```java
public class Test {

    public static void main(String[] args) throws IOException, ClassNotFoundException {
        // 序列化
        File file = new File("user");
        FileOutputStream fos = new FileOutputStream(file);
        ObjectOutput oos = new ObjectOutputStream(fos);
        oos.writeObject(new User("Tom"));
        oos.flush();

        // 反序列化
        FileInputStream fis = new FileInputStream(file);
        ObjectInputStream ois = new ObjectInputStream(fis);
        User user = (User) ois.readObject();
        System.out.println(user.getName());
    }
}

class User implements Serializable {

    private String name;

    public User(String name) {
        this.name = name;
    }

    public String getName() {
        return name;
    }
}
```

#### 1.6. 获取 Class 对象有几种方式？有什么区别？

三种方式都返回 Class对象，不同之处在于：

1. 类名.class：只做类的加载（前提是类没有被加载过），不做初始化工作
2. Class.forName("类名")：加载类并做类的静态初始化，需要进行异常捕获，可能会抛出 ClassNotFoundException
3. 对象实例调用 getClass() 方法：对类进行加载并进行静态初始化、动态初始化

#### 1.7. Object 类有哪些方法？

1. getClass()：获取实例对应的类对象
2. hashCode()：返回一个整型数值，默认返回内存地址，可以通过 JVM 参数配置
3. equals()：比较两个对象是否相等，默认使用 == 进行比较，比较的是内存地址
4. clone()：克隆方法，实现了 Cloneable 接口的类可以调用该方法，否则会抛出 CloneNotSupportedException
5. toString()：返回一个 String 对象，一般子类都有覆盖。默认返回格式如下：对象的 **class 名称 + @ + hashCode** 的十六进制字符串。
6. notify()：随机唤醒一个在该对象等待池的某个线程
7. notifyAll()：唤醒在该对象等待池的所有线程，优先级高的线程竞争到对象锁的概率大
8. wait()：使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁
9. finalize()：主要用于在 GC 的时候再次被调用。当垃圾回收器要宣告一个对象死亡时，至少要经过两次标记过程：如果对象在进行可达性分析后发现没有和 GC Roots 相连接的引用链，就会被第一次标记，并且判断是否执行 finalize( ) 方法，如果对象覆盖 finalize( )方法且未被虚拟机调用过，那么这个对象会被放置在 F-Queue 队列中，并在稍后由一个虚拟机自动建立的低优先级的 Finalizer 线程区执行触发 finalizer( ) 方法，但不承诺等待其运行结束。 作用是为了给对象最后一次逃脱的机会。

#### 1.8. JDK8 新特性及实际应用.

1. 函数式接口：就是说函数可以作为另一个函数的参数。函数式接口，要求接口中**有且仅有一个抽象方法**，因此经常使用的Runnable，Callable接口就是典型的函数式接口。可以使用`@FunctionalInterface`注解，声明一个接口是函数式接口。
2. Lambda 表达式：就是匿名函数，可以作为参数直接传递给调用者
3. Stream API：是对集合对象功能的增强，提供了各种非常便利、高效的操作
4. 新的时间和日期的 API
5. 其它新特性：如 HashMap、ConcurrentHashMap的结构变化

#### 1.9. 快速失败和安全失败.

**快速失败**

迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变 modCount 的值。每当迭代器遍历下一个元素之前，都会检测 modCount 变量是否为 expectedmodCount 值，是的话就返回遍历；否则抛出异常，终止遍历。java.util 包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。

**安全失败**

采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发ConcurrentModificationException。基于拷贝内容的优点是避免了ConcurrentModificationException，但同样地，迭代器并不能访问到修改后的内容，也就是说迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。java.util.concurrent 包下的容器都是安全失败，可以在多线程下并发使用，并发修改。

#### 1.10. 线程和进程的区别.

进程是程序的一次执行，是系统进行资源分配和调度的独立单位，他的作用是是程序能够并发执行提高资源利用率和吞吐率。由于进程是资源分配和调度的基本单位，因为进程的创建、销毁、切换产生大量的时间和空间的开销，进程的数量不能太多。

线程是比进程更小的能独立运行的基本单位，他是进程的一个实体，可以减少程序并发执行时的时间和空间开销，使得操作系统具有更好的并发性。线程基本不拥有系统资源，只有一些运行时必不可少的资源，比如程序计数器、寄存器和栈，进程则占有堆、栈，共享进程的其它资源。

#### 1.11. 对象的内存布局.

在 Hotspot 虚拟机中，对象在内存中的布局包含三个部分：

1. 对象头
   1. Mark Word：包含对象的hashcode、分代年龄、轻量级锁指针、重量级锁指针、GC标记、偏向锁线程ID、偏向锁时间戳
   2. Class Pointer：指向类的元数据的指针，通过这个指针才能确定对象是属于哪个类的实例。
2. 实例数据：包含了所有成员变量
3. 对齐填充

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehqwibXA66l7WiaIxZx91PaPNjz8NDfYYvlm2tmWUjOIknNdYweYEBINzw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 1.12. synchronized 原理.

synchronized 是 java 提供的原子性内置锁，也称为监视器锁，使用 synchronized 后，会在编译之后在同步代码块前后加上 monitorennter 和 monitorexit 字节码指令，它依赖操作系统底层互斥锁实现。synchronized 的主要所用是实现原子性操作和解决共享变量内存可见性问题。

执行monitorenter指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器+1。此时其他竞争锁的线程则会进入等待队列中。

执行monitorexit指令时则会把计数器-1，当计数器值为0时，则锁释放，处于等待队列中的线程再继续竞争锁。

synchronized是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁，而且由于Java中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时时会从用户态切换到内核态，这种转换非常消耗性能。

从内存语义来说，加锁的过程会清除工作内存中的共享变量，再从主内存读取，而释放锁的过程则是将工作内存中的共享变量写回主内存。

*实际上大部分时候我认为说到monitorenter就行了，但是为了更清楚的描述，还是再具体一点*。

如果再深入到源码来说，synchronized实际上有两个队列waitSet和entryList。

1. 当多个线程进入同步代码块时，首先进入entryList

2. 有一个线程获取到 monitor 锁后，就赋值给当前线程，并且计数器+1

3. 如果线程调用wait方法，将释放锁，当前线程置为null，计数器-1，同时进入waitSet等待被唤醒，调用notify或者notifyAll之后又会进入entryList竞争锁

4. 如果线程执行完毕，同样释放锁，计数器-1，当前线程置为null

   ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehVayU2Ey8Fm3lFvDoaSjT2prBjWibRkk2tB1ric2LHVDCXYicyK2gb195Q/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 1.13. 锁的类型有哪些

###### 1.13.1. 乐观锁 VS 悲观锁

乐观锁和悲观锁是一种广义上的概念，体现了看待线程的不同角度。

**悲观锁**：对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候先加锁，确保数据不会被其它线程修改，Java中的synchronized和Lock的实现类都是悲观锁。

**乐观锁**：乐观锁认为自己在修改数据的时候不会有别的线程修改数据，所以不会加锁，只是在更新数据的时候判断有没有别的线程更新了这个数据，如果这个数据没有被更新，当前线程将自己修改的数据成功写入，如果数据已经被其它线程修改，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。Java中乐观锁是通过无锁编程来实现的，最常用的是CAS算法，Java原子类中的递增操作就是通过CAS自旋实现的。

###### 1.13.2. 自旋锁 VS 适应性自旋锁

阻塞和唤醒一个Java线程需要系统切换CPU的状态来完成，这种状态转换需要消耗时间，如果同步块中的内容过于简单，状态转换的时间可能比同步块代码执行的时间还要长

**自旋锁**：同步资源的锁被一个线程持有时，后来请求的线程不放弃CPU的时间片，进行自旋，在自旋完成后如果前面的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。

 自旋锁虽然避免了线程切换的开销，但是它要占用处理器时间，如果锁被占用的时间很短，自旋的效果就会很好，反之只会白白浪费处理器资源，所以自旋等待的时间要有一定的限度，如果自旋超过了次数没有成功获取到锁（默认为10次，XX:PreBlockSpin来更改），就挂起线程。自旋锁的实现原理也是CAS。

**适应性自旋锁**：如果在同一个锁对象上，自旋等待刚刚成功获得过锁，那么虚拟机就会认为这次自旋有可能会再次成功，进而它将允许自旋等待持续相对更长的时间，如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时，将可能省略掉自旋锁过程，直接阻塞线程，避免浪费处理器资源。

###### 1.13.3. 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁

这四种锁是指锁的状态，专门针对synchronized的，锁的状态一共有四种，只能升级不能降级

**无锁**：没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能够修改成功。修改操作在循环内进行，线程会不断尝试修改共享资源。CAS原理就是无锁的实现，无锁无法全面代替有锁，但是在某些场合下是非常高效的

**偏向锁**：目标就是在只有一个线程执行代码块的时候提高性能。当一个线程访问同步块并获取锁时，会在对象头的Mark word里存储锁偏向的线程id，在线程进入和退出时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储了指向当前线程的偏向锁只有当遇到其它线程竞争时偏向锁时，持有偏向锁的线程才会释放锁。默认开启，可以通过-XX:-UseBiasedLocking=false来关闭，关闭之后默认进入轻量级锁。

**轻量级锁**：当锁是偏向锁时，被另外的线程访问就会升级为轻量级锁，其它线程会通过自旋的方式获取锁，不会阻塞。如果当前只有一个等待线程，该线程通过自旋等待。当线程自旋超过一定次数或者一个线程持有锁，一个线程在自旋，又有第三个线程来访问时，轻量级锁升级为重量级锁。

**重量级锁**：升级为重量级锁的时候，等待锁的线程会进入阻塞状态。

###### 1.13.4. 公平锁 VS 非公平锁

ReentrantLock默认使用非公平锁，可以通过构造器显式使用公平锁

**公平锁**：多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队。优点是线程不会饿死。缺点是等待队列中除第一个线程外的所有线程都会阻塞，CPU唤醒线程的开销比非公平锁大。

**非公平锁**：多个线程加锁时直接获取锁，如果获取不到才会到队尾等待。如果此时锁刚好可用，那么这个线程无需阻塞直接获取到锁。优点是非公平锁可能会出现后申请锁的线程先获取锁的场景，线程有几率不阻塞直接获取锁，可以减少唤起线程的开销。缺点是处于等待队列中的线程可能会饿死，或者要等很久才能获取到锁。

###### 1.13.5. 可重入锁 VS 非可重入锁

**可重入锁**：嵌套调用时可以自动获取锁，synchronized和ReentrantLock都是可重入锁

**非可重入锁**：与之相反

###### 1.13.6. 独享锁 VS 共享锁

**独享锁（拍它锁）**：锁一次只能被一个线程持有

**共享锁**：如果一个线程对共享数据加上共享锁后，其它线程只能对共享数据再加共享锁，不能加拍它锁，获得共享锁的线程只能读数据，不能修改数据

#### 1.14. 简述锁优化机制.

从JDK1.6版本之后，synchronized本身也在不断优化锁的机制，有些情况下他并不会是一个很重量级的锁了。优化机制包括自适应锁、自旋锁、锁消除、锁粗化、轻量级锁和偏向锁。

锁的状态从低到高依次为**无锁->偏向锁->轻量级锁->重量级锁**，升级的过程就是从低到高，降级在一定条件也是有可能发生的。

**自旋锁**：由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短，所有没有必要挂起线程，用户态和内核态的来回上下文切换严重影响性能。自旋的概念就是让线程执行一个忙循环，可以理解为就是啥也不干，防止从用户态转入内核态，自旋锁可以通过设置-XX:+UseSpining来开启，自旋的默认次数是10次，可以使用-XX:PreBlockSpin设置。

**自适应锁**：自适应锁就是自适应的自旋锁，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状态来决定。

**锁消除**：锁消除指的是JVM检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。

**锁粗化**：锁粗化指的是有很多操作都是对同一个对象进行加锁，就会把锁的同步范围扩展到整个操作序列之外。

**偏向锁**：当线程访问同步块获取锁时，会在对象头和栈帧中的锁记录里存储偏向锁的线程ID，之后这个线程再次进入同步块时都不需要CAS来加锁和解锁了，偏向锁会永远偏向第一个获得锁的线程，如果后续没有其他线程获得过这个锁，持有锁的线程就永远不需要进行同步，反之，当有其他线程竞争偏向锁时，持有偏向锁的线程就会释放偏向锁。可以用过设置-XX:+UseBiasedLocking开启偏向锁。

**轻量级锁**：JVM的对象的对象头中包含有一些锁的标志位，代码进入同步块的时候，JVM将会使用CAS方式来尝试获取锁，如果更新成功则会把对象头中的状态位标记为轻量级锁，如果更新失败，当前线程就尝试自旋来获得锁。

整个锁升级的过程非常复杂，我尽力去除一些无用的环节，简单来描述整个升级的机制。

简单点说，偏向锁就是通过对象头的偏向线程ID来对比，甚至都不需要CAS了，而轻量级锁主要就是通过CAS修改对象头锁记录和自旋来实现，重量级锁则是除了拥有锁的线程其他全部阻塞。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehP1heYUUerKq0Xd3k7DGl9xqicy6NsgJow4xHIYSK0Oc90aN7TO2TsibA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"  />

#### 1.15. 简述 ReentrantLock 原理及和 synchronized 有的区别？

相比于synchronized，ReentrantLock需要显式的获取锁和释放锁，相对现在基本都是用JDK7和JDK8的版本，ReentrantLock的效率和synchronized区别基本可以持平了。他们的主要区别有以下几点：

1. 等待可中断，当持有锁的线程长时间不释放锁的时候，等待中的线程可以选择放弃等待，转而处理其他的任务。
2. 公平锁：synchronized和ReentrantLock默认都是非公平锁，但是ReentrantLock可以通过构造函数传参改变。只不过使用公平锁的话会导致性能急剧下降。
3. 绑定多个条件：ReentrantLock可以同时绑定多个Condition条件对象。

ReentrantLock基于AQS(AbstractQueuedSynchronizer 抽象队列同步器)实现。

AQS内部维护一个state状态位，尝试加锁的时候通过CAS(CompareAndSwap)修改值，如果成功设置为1，并且把当前线程ID赋值，则代表加锁成功，一旦获取到锁，其他的线程将会被阻塞进入阻塞队列自旋，获得锁的线程释放锁的时候将会唤醒阻塞队列中的线程，释放锁的时候则会把state重新置为0，同时当前线程ID置为空。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehjaoTsjWvmlr4VwFnX8ZHGh8xUPt87pI4iaYBOoltaT7zWibDqrO1HouA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 1.16. 简述 CAS 原理，CAS 有什么缺点？

###### 1.16.1. CAS原理

操作流程是线程在读取数据时不进行加锁，在准备写回数据时，比较原值是否修改，如果未被其它线程修改则写回数据，如果已被修改，则重新执行读取流程。这是一种乐观策略，认为并发操作并不总会发生。JUC中很多工具类都是基于CAS实现的，比如原子操作类调用了UnSafe类中的CAS算法，从CPU指令级别来实现无锁自增，所以CAS比synchronized的锁效率高很多。

###### 1.16.2. CAS缺点

**ABA问题**：ABA 的问题指的是在 CAS 更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是A，但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。只是ABA的问题大部分场景下都不影响并发的最终效果。

Java中有AtomicStampedReference来解决这个问题，他加入了预期标志和更新后标志两个字段，更新时不光检查值，还要检查当前的标志是否等于预期标志，全部相等的话才会更新。

**循环时间长开销大**：自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。

**只能保证一个共享变量的原子操作**：只对一个共享变量操作可以保证原子性，但是多个则不行，多个可以通过AtomicReference来处理或者使用锁synchronized实现。

#### 1.17. 简述 HashMap 原理.

HashMap主要由数组和链表组成，他不是线程安全的。核心的点就是put插入数据的过程，get查询数据以及扩容的方式。JDK1.7和1.8的主要区别在于头插和尾插方式的修改，头插容易导致HashMap链表死循环，并且1.8之后加入红黑树对性能有提升。

**put插入数据流程**

往map插入元素的时候首先通过对key hash然后与数组长度-1进行与运算((n-1)&hash)，都是2的次幂所以等同于取模，但是位运算的效率更高。找到数组中的位置之后，如果数组中没有元素直接存入，反之则判断key是否相同，key相同就覆盖，否则就会插入到链表的尾部，如果链表的长度超过8，则会转换成红黑树，最后判断数组长度是否超过默认的长度*负载因子也就是12，超过则进行扩容。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehhYJqIVUVqkQmiaXVoachgswvKcUfQ5AdgbJpYngXOvicVTDub1KxYMsw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**get查询数据**

查询数据相对来说就比较简单了，首先计算出hash值，然后去数组查询，是红黑树就去红黑树查，链表就遍历链表查询就可以了。

**resize扩容过程**

扩容的过程就是对key重新计算hash，然后把数据拷贝到新的数组。

#### 1.18. 多线程环境下如何使用 Map？简述 ConcurrentHashmap 原理.

多线程环境可以使用Collections.synchronizedMap同步加锁的方式，还可以使用HashTable，但是同步的方式显然性能不达标，而ConurrentHashMap更适合高并发场景使用。

ConcurrentHashmap在JDK1.7和1.8的版本改动比较大，1.7使用Segment+HashEntry分段锁的方式实现，1.8则抛弃了Segment，改为使用CAS+synchronized+Node实现，同样也加入了红黑树，避免链表过长导致性能的问题。

**1.7-分段锁**

从结构上说，1.7版本的ConcurrentHashMap采用分段锁机制，里面包含一个Segment数组，Segment继承与ReentrantLock，Segment则包含HashEntry的数组，HashEntry本身就是一个链表的结构，具有保存key、value的能力能指向下一个节点的指针。

实际上就是相当于每个Segment都是一个HashMap，默认的Segment长度是16，也就是支持16个线程的并发写，Segment之间相互不会受到影响。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehq0unBKlKXBhARwBmeYWZJFgiaXCX2zCTjMk0Xq3gduRqI6fsR2ao9Hw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**put流程**

其实发现整个流程和HashMap非常类似，只不过是先定位到具体的Segment，然后通过ReentrantLock去操作而已，后面的流程我就简化了，因为和HashMap基本上是一样的。

1. 计算hash，定位到segment，segment如果是空就先初始化
2. 使用ReentrantLock加锁，如果获取锁失败则尝试自旋，自旋超过次数就阻塞获取，保证一定获取锁成功
3. 遍历HashEntry，就是和HashMap一样，数组中key和hash一样就直接替换，不存在就再插入链表，链表同样

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPeh5Ua8JnShvjMmVbqbnG4SBeM0XbGC7XicL1tyic2ZsCLUM8doxianE5W9w/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**get流程**

get也很简单，key通过hash定位到segment，再遍历链表定位到具体的元素上，需要注意的是value是volatile的，所以get是不需要加锁的。

**1.8-CAS+synchronized**

1.8抛弃分段锁，转为用CAS+synchronized来实现，同样HashEntry改为Node，也加入了红黑树的实现。主要还是看put的流程。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehOaIZhNNGIw92iaLxnZW4PsxRN64LOy5vZCLrOcjf22f4umKTgtEU9TQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**put流程**

1. 首先计算hash，遍历node数组，如果node是空的话，就通过CAS+自旋的方式初始化
2. 如果当前数组位置是空则直接通过CAS自旋写入数据
3. 如果hash==MOVED，说明需要扩容，执行扩容
4. 如果都不满足，就使用synchronized写入数据，写入数据同样判断链表、红黑树，链表写入和HashMap的方式一样，key hash一样就覆盖，反之就尾插法，链表长度超过8就转换成红黑树

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehSWXgNAwd00W76yvhUsqNK8uztPmTQwzicee3zNic0po5hjZILceUTiaCg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**get查询**

get很简单，通过key计算hash，如果key hash相同就返回，如果是红黑树按照红黑树获取，都不是就遍历链表获取。

#### 1.19. 简述 volatile 原理.

1. 相比synchronized的加锁方式来解决共享变量的内存可见性问题，volatile就是更轻量的选择，他没有上下文切换的额外开销成本。使用volatile声明的变量，可以确保值被更新的时候对其他线程立刻可见。volatile使用内存屏障来保证不会发生指令重排，解决了内存可见性的问题。

   我们知道，线程都是从主内存中读取共享变量到工作内存来操作，完成之后再把结果写会主内存，但是这样就会带来可见性问题。举个例子，假设现在我们是两级缓存的双核CPU架构，包含L1、L2两级缓存。

   1. 线程A首先获取变量X的值，由于最初两级缓存都是空，所以直接从主内存中读取X，假设X初始值为0，线程A读取之后把X值都修改为1，同时写回主内存。这时候缓存和主内存的情况如下图。

   <img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPeh2IXL5iaBEibeGqJKKHl3Gf731F1eqUlsWUUZKIgBuvZicV9Xb7WuSkGqQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

   1. 线程B也同样读取变量X的值，由于L2缓存已经有缓存X=1，所以直接从L2缓存读取，之后线程B把X修改为2，同时写回L2和主内存。这时候的X值入下图所示。

      那么线程A如果再想获取变量X的值，因为L1缓存已经有x=1了，所以这时候变量内存不可见问题就产生了，B修改为2的值对A来说没有感知。

      <img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehzJKtGbqLVwjSh0MvYUVQg9ygbGhIVKSD5bK5V1ibtcYgRlKLVnasuEw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />i

   那么，如果X变量用volatile修饰的话，当线程A再次读取变量X的话，CPU就会根据缓存一致性协议强制线程A重新从主内存加载最新的值到自己的工作内存，而不是直接用缓存中的值。

   再来说内存屏障的问题，volatile修饰之后会加入不同的内存屏障来保证可见性的问题能正确执行。这里写的屏障基于书中提供的内容，但是实际上由于CPU架构不同，重排序的策略不同，提供的内存屏障也不一样，比如x86平台上，只有StoreLoad一种内存屏障。

   1. StoreStore屏障，保证上面的普通写不和volatile写发生重排序
   2. StoreLoad屏障，保证volatile写与后面可能的volatile读写不发生重排序
   3. LoadLoad屏障，禁止volatile读与后面的普通读重排序
   4. LoadStore屏障，禁止volatile读和后面的普通写重排序

   <img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehWmicawj6sLn1eYoBoPYlPUfFJHHV9jVaTtIy7al6m58Zp6MMtXsOl7g/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;"/>

#### 1.20. 简述对 JMM 内存模型的理解？为什么需要 JMM？

本身随着CPU和内存的发展速度差异的问题，导致CPU的速度远快于内存，所以现在的CPU加入了高速缓存，高速缓存一般可以分为L1、L2、L3三级缓存。基于上面的例子我们知道了这导致了缓存一致性的问题，所以加入了缓存一致性协议，同时导致了内存可见性的问题，而编译器和CPU的重排序导致了原子性和有序性的问题，JMM内存模型正是对多线程操作下的一系列规范约束，因为不可能让陈雇员的代码去兼容所有的CPU，通过JMM我们才屏蔽了不同硬件和操作系统内存的访问差异，这样保证了Java程序在不同的平台下达到一致的内存访问效果，同时也是保证在高效并发的时候程序能够正确执行。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehfsHXibmwFS8CsYP1MkEr6PEJMfic9qfA5fqq9ic3XWIic7sgTOkJVtkIMg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

**原子性**：Java内存模型通过read、load、assign、use、store、write来保证原子性操作，此外还有lock和unlock，直接对应着synchronized关键字的monitorenter和monitorexit字节码指令。

**可见性**：可见性的问题在上面的回答已经说过，Java保证可见性可以认为通过volatile、synchronized、final来实现。

**有序性**：由于处理器和编译器的重排序导致的有序性问题，Java通过volatile、synchronized来保证。

**happen-before规则**

虽然指令重排提高了并发的性能，但是Java虚拟机会对指令重排做出一些规则限制，并不能让所有的指令都随意的改变执行位置，主要有以下几点：

1. 单线程每个操作，happen-before于该线程中任意后续操作
2. volatile写happen-before与后续对这个变量的读
3. synchronized解锁happen-before后续对这个锁的加锁
4. final变量的写happen-before于final域对象的读，happen-before后续对final变量的读
5. 传递性规则，A先于B，B先于C，那么A一定先于C发生

**工作内存和主内存**

主内存可以认为就是物理内存，Java内存模型中实际就是虚拟机内存的一部分。而工作内存就是CPU缓存，他有可能是寄存器也有可能是L1\L2\L3缓存，都是有可能的。

#### 1.21. 简述 ThreadLocal 原理.

ThreadLocal 可以理解为线程本地变量，他会在每个线程都创建一个副本，那么在线程之间访问内部副本变量就行了，做到了线程之间互相隔离，相比于 synchronized 的做法是用空间来换时间。

ThreadLocal 有一个静态内部类 ThreadLocalMap，ThreadLocalMap 又包含了一个 Entry 数组，Entry 本身是一个弱引用，他的 key 是指向 ThreadLocal 的弱引用，Entry 具备了保存 key value 键值对的能力。

弱引用的目的是为了防止内存泄露，如果是强引用那么 ThreadLocal 对象除非线程结束否则始终无法被回收，弱引用则会在下一次 GC 的时候被回收。

但是这样还是会存在内存泄露的问题，假如 key 和 ThreadLocal 对象被回收之后，entry 中就存在 key 为 null，但是 value 有值的 entry 对象，但是永远没办法被访问到，同样除非线程结束运行。

但是只要 ThreadLocal 使用恰当，在使用完之后调用 remove 方法删除 Entry 对象，实际上是不会出现这个问题的。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehlyogmxkbKb9Sibtp5k8lz73a2AlyVgerJAtfmibhIic38dJh38NF0QYZA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 1.22. 引用类型有哪些？有什么区别？

引用类型主要分为强软弱虚四种：

1. 强引用指的就是代码中普遍存在的赋值方式，比如 **A a = new A()** 这种。强引用关联的对象，永远不会被 GC 回收。
2. 软引用可以用 SoftReference 来描述，指的是那些有用但是不是必须要的对象。系统在发生内存溢出前会对这类引用的对象进行回收。
3. 弱引用可以用 WeakReference 来描述，他的强度比软引用更低一点，弱引用的对象下一次GC的时候一定会被回收，而不管内存是否足够。
4. 虚引用也被称作幻影引用，是最弱的引用关系，可以用 PhantomReference 来描述，他必须和 ReferenceQueue 一起使用，同样的当发生 GC 的时候，虚引用也会被回收。可以用虚引用来管理堆外内存。

#### 1.23. 简述线程池原理，线程池的拒绝策略有哪些？

首先线程池有几个核心的参数概念：

1. 最大线程数 maximumPoolSize
2. 核心线程数 corePoolSize
3. 活跃时间 keepAliveTime
4. 阻塞队列 workQueue
5. 拒绝策略 RejectedExecutionHandler

当提交一个新任务到线程池时，具体的执行流程如下：

1. 当我们提交任务，线程池会根据 corePoolSize 大小创建若干任务数量线程执行任务.
2. 当任务的数量超过 corePoolSize 数量，后续的任务将会进入阻塞队列阻塞排队.
3. 当阻塞队列也满了之后，那么将会继续创建 (maximumPoolSize-corePoolSize) 个数量的线程来执行任务，如果任务处理完成，maximumPoolSize-corePoolSize 额外创建的线程等待 keepAliveTime 之后被自动销毁.
4. 如果达到 maximumPoolSize，阻塞队列还是满的状态，那么将根据不同的拒绝策略对应处理.

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehFlVhBew4SJXUzCicAjSkHdwXoLCaOMI7x2HhamkQqvHoBd1Zw9LS6OQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

线程池的拒绝策略主要有四种：

主要有4种拒绝策略：

1. AbortPolicy：直接丢弃任务，抛出异常，这是默认策略.
2. CallerRunsPolicy：只用调用者所在的线程来处理任务.
3. DiscardOldestPolicy：丢弃等待队列中最旧的任务，并执行当前任务.
4. DiscardPolicy：直接丢弃任务，也不抛出异常.

#### 1.24. 多线程如何避免死锁？

一个线程获得锁，如果其它线程也想获得相同的锁就会被阻塞，等待持有锁的线程释放锁；比如线程A已经获得锁1，这时要获得锁2，线程B已经获得锁2，还要获得锁1，线程A和线程B互相等待对方释放锁，此时就会发生死锁；

**如何定位死锁**：

使用jps，查看Java虚拟机的pid

使用jstack，打印堆栈信息，可以查看线程的状态以及持有的锁

**如何避免死锁**：

按顺序获取锁：每个线程获取锁时，按照顺序获取锁

获取锁时限：在获取锁时如果超过这个时限则放弃对该锁的请求

#### 1.25. 线程池有几种类型？

- newSingleThreadExecutor：一个单线程的线程池。如果因异常结束，会再创建一个新的，保证按照提交顺序执行。
- newFixedThreadPool：创建固定大小的线程池。根据提交的任务逐个增加线程，直到最大值保持不变。如果因异常结束，会新创建一个线程补充。
- newCachedThreadPool：创建一个可缓存的线程池。会根据任务自动新增或回收线程。
- newScheduledThreadPool：支持定时以及周期性执行任务的需求。
- newWorkStealingPool：JDK8新增，根据所需的并行层次来动态创建和关闭线程，通过使用多个队列减少竞争，底层使用ForkJoinPool来实现。优势在于可以充分利用多CPU，把一个任务拆分成多个“小任务”，放到多个处理器核心上并行执行；当多个“小任务”执行完成之后，再将这些执行结果合并起来即可。

#### 1.26. 简述 CountDownLatch，CyclicBarrier，Semaphore 的原理

###### 1.26.1. CountDownLatch

CountDownLatch 适用于在多线程的场景需要等待所有子线程全部执行完毕之后再做操作的场景。

举个例子，早上部门开会，有人在上厕所，这时候需要等待所有人从厕所回来之后才能开始会议。

```java
public class CountDownLatchTest {
    private static int num = 3;
    private static CountDownLatch countDownLatch = new CountDownLatch(num);
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);
    public static void main(String[] args) throws Exception{
        executorService.submit(() -> {
            System.out.println("A在上厕所");
            try {
                Thread.sleep(4000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                countDownLatch.countDown();
                System.out.println("A上完了");
            }
        });
        executorService.submit(()->{
            System.out.println("B在上厕所");
            try {
                Thread.sleep(2000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                countDownLatch.countDown();
                System.out.println("B上完了");
            }
        });
        executorService.submit(()->{
            System.out.println("C在上厕所");
            try {
                Thread.sleep(3000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                countDownLatch.countDown();
                System.out.println("C上完了");
            }
        });

        System.out.println("等待所有人从厕所回来开会...");
        countDownLatch.await();
        System.out.println("所有人都好了，开始开会...");
        executorService.shutdown();

    }
}
```

代码执行结果：

```java
A在上厕所
B在上厕所
等待所有人从厕所回来开会...
C在上厕所
B上完了
C上完了
A上完了
所有人都好了，开始开会...
```

初始化一个CountDownLatch实例传参3，因为我们有3个子线程，每次子线程执行完毕之后调用countDown()方法给计数器-1，主线程调用await()方法后会被阻塞，直到最后计数器变为0，await()方法返回，执行完毕。他和join()方法的区别就是join会阻塞子线程直到运行结束，而CountDownLatch可以在任何时候让await()返回，而且用ExecutorService没法用join了，相比起来，CountDownLatch更灵活。

CountDownLatch基于AQS实现，volatile变量state维持倒数状态，多线程共享变量可见。

1. CountDownLatch通过构造函数初始化传入参数实际为AQS的state变量赋值，维持计数器倒数状态
2. 当主线程调用await()方法时，当前线程会被阻塞，当state不为0时进入AQS阻塞队列等待。
3. 其他线程调用countDown()时，state值原子性递减，当state值为0的时候，唤醒所有调用await()方法阻塞的线程

###### 1.26.2. CyclicBarrier

CyclicBarrier叫做回环屏障，它的作用是**让一组线程全部达到一个状态之后再全部同时执行**，而且他有一个特点就是所有线程执行完毕之后是可以重用的。

```java
public class CyclicBarrierTest {
    private static int num = 3;
    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(num, () -> {
        System.out.println("所有人都好了，开始开会...");
        System.out.println("-------------------");
    });
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);
    public static void main(String[] args) throws Exception{
        executorService.submit(() -> {
            System.out.println("A在上厕所");
            try {
                Thread.sleep(4000);
                System.out.println("A上完了");
                cyclicBarrier.await();
                System.out.println("会议结束，A退出");
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()->{
            System.out.println("B在上厕所");
            try {
                Thread.sleep(2000);
                System.out.println("B上完了");
                cyclicBarrier.await();
                System.out.println("会议结束，B退出");
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()->{
            System.out.println("C在上厕所");
            try {
                Thread.sleep(3000);
                System.out.println("C上完了");
                cyclicBarrier.await();
                System.out.println("会议结束，C退出");
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });

        executorService.shutdown();

    }
}
```

输出结果为：

```java
A在上厕所
B在上厕所
C在上厕所
B上完了
C上完了
A上完了
所有人都好了，开始开会...
-------------------
会议结束，A退出
会议结束，B退出
会议结束，C退出
```

从结果来看和CountDownLatch非常相似，初始化传入3个线程和一个任务，线程调用await()之后进入阻塞，计数器-1，当计数器为0时，就去执行CyclicBarrier中构造函数的任务，当任务执行完毕后，唤醒所有阻塞中的线程。这验证了CyclicBarrier**让一组线程全部达到一个状态之后再全部同时执行**的效果。

再举个例子来验证CyclicBarrier可重用的效果。

```java
public class CyclicBarrierTest2 {
    private static int num = 3;
    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(num, () -> {
        System.out.println("-------------------");
    });
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);

    public static void main(String[] args) throws Exception {
        executorService.submit(() -> {
            System.out.println("A在上厕所");
            try {
                Thread.sleep(4000);
                System.out.println("A上完了");
                cyclicBarrier.await();
                System.out.println("会议结束，A退出，开始撸代码");
                cyclicBarrier.await();
                System.out.println("C工作结束，下班回家");
                cyclicBarrier.await();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {

            }
        });
        executorService.submit(() -> {
            System.out.println("B在上厕所");
            try {
                Thread.sleep(2000);
                System.out.println("B上完了");
                cyclicBarrier.await();
                System.out.println("会议结束，B退出，开始摸鱼");
                cyclicBarrier.await();
                System.out.println("B摸鱼结束，下班回家");
                cyclicBarrier.await();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {

            }
        });
        executorService.submit(() -> {
            System.out.println("C在上厕所");
            try {
                Thread.sleep(3000);
                System.out.println("C上完了");
                cyclicBarrier.await();
                System.out.println("会议结束，C退出，开始摸鱼");
                cyclicBarrier.await();
                System.out.println("C摸鱼结束，下班回家");
                cyclicBarrier.await();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {

            }
        });

        executorService.shutdown();

    }
}
```

输出结果：

```java
A在上厕所
B在上厕所
C在上厕所
B上完了
C上完了
A上完了
-------------------
会议结束，A退出，开始撸代码
会议结束，B退出，开始摸鱼
会议结束，C退出，开始摸鱼
-------------------
C摸鱼结束，下班回家
C工作结束，下班回家
B摸鱼结束，下班回家
-------------------
```

从结果来看，每个子线程调用await()计数器减为0之后才开始继续一起往下执行，会议结束之后一起进入摸鱼状态，最后一天结束一起下班，这就是**可重用**。

CyclicBarrier还是基于AQS实现的，内部维护parties记录总线程数，count用于计数，最开始count=parties，调用await()之后count原子递减，当count为0之后，再次将parties赋值给count，这就是复用的原理。

1. 当子线程调用await()方法时，获取独占锁，同时对count递减，进入阻塞队列，然后释放锁
2. 当第一个线程被阻塞同时释放锁之后，其他子线程竞争获取锁，操作同1
3. 直到最后count为0，执行CyclicBarrier构造函数中的任务，执行完毕之后子线程继续向下执行

###### 1.26.3. Semaphore

Semaphore叫做信号量，和前面两个不同的是，他的计数器是递增的。

```java
public class SemaphoreTest {
    private static int num = 3;
    private static int initNum = 0;
    private static Semaphore semaphore = new Semaphore(initNum);
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);
    public static void main(String[] args) throws Exception{
        executorService.submit(() -> {
            System.out.println("A在上厕所");
            try {
                Thread.sleep(4000);
                semaphore.release();
                System.out.println("A上完了");
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()->{
            System.out.println("B在上厕所");
            try {
                Thread.sleep(2000);
                semaphore.release();
                System.out.println("B上完了");
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()->{
            System.out.println("C在上厕所");
            try {
                Thread.sleep(3000);
                semaphore.release();
                System.out.println("C上完了");
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });

        System.out.println("等待所有人从厕所回来开会...");
        semaphore.acquire(num);
        System.out.println("所有人都好了，开始开会...");

        executorService.shutdown();

    }
}
```

输出结果为：

```java
A在上厕所
B在上厕所
等待所有人从厕所回来开会...
C在上厕所
B上完了
C上完了
A上完了
所有人都好了，开始开会...
```

稍微和前两个有点区别，构造函数传入的初始值为0，当子线程调用release()方法时，计数器递增，主线程acquire()传参为3则说明主线程一直阻塞，直到计数器为3才会返回。

Semaphore还是基于AQS实现的，同时获取信号量有公平和非公平两种策略

1. 主线程调用acquire()方法时，用当前信号量值-需要获取的值，如果小于0，则进入同步阻塞队列，大于0则通过CAS设置当前信号量为剩余值，同时返回剩余值
2. 子线程调用release()给当前信号量值计数器+1(增加的值数量由传参决定)，同时不停的尝试因为调用acquire()进入阻塞的线程

**总结**

CountDownLatch通过计数器提供了比join更灵活的多线程控制方式，CyclicBarrier也可以达到CountDownLatch的效果，而且有可复用的特点，Semaphore则是采用信号量递增的方式，开始的时候并不需要关注需要同步的线程个数，并且提供获取信号的公平和非公平策略。

----

## 2. JVM

#### 2.1. 简述内存布局

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIdxx34IBCxK8JZLARaNrnvVpOMwS07FaicpOh5E0zEeLfAdT2AyroNdA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**1. 堆**：堆Java虚拟机中最大的一块内存，是线程共享的内存区域，基本上所有的对象实例数组都是在堆上分配空间。堆区细分为Yound区年轻代和Old区老年代，其中年轻代又分为Eden、S0、S1 3个部分，他们默认的比例是8:1:1的大小。

**2. 栈**：栈是线程私有的内存区域，每个方法执行的时候都会在栈创建一个栈帧，方法的调用过程就对应着栈的入栈和出栈的过程。每个栈帧的结构又包含局部变量表、操作数栈、动态连接、方法返回地址。

局部变量表用于存储方法参数和局部变量。当第一个方法被调用的时候，他的参数会被传递至从0开始的连续的局部变量表中。

操作数栈用于一些字节码指令从局部变量表中传递至操作数栈，也用来准备方法调用的参数以及接收方法返回结果。

动态连接用于将符号引用表示的方法转换为实际方法的直接引用。

**3. 元数据**：在Java1.7之前，包含方法区的概念，常量池就存在于方法区（永久代）中，而方法区本身是一个逻辑上的概念，在1.7之后则是把常量池移到了堆内，1.8之后移出了永久代的概念(方法区的概念仍然保留)，实现方式则是现在的元数据。它包含类的元信息和运行时常量池。Class文件就是类和接口的定义信息。运行时常量池就是类和接口的常量池运行时的表现形式。

**4. 本地方法栈**：主要用于执行本地native方法的区域

**5. 程序计数器**：也是线程私有的区域，用于记录当前线程下虚拟机正在执行的字节码的指令地址

#### 2.2. 简述 new 一个对象的过程。

当虚拟机遇见 new 关键字时，首先判断当前累是否已经加载，如果类没有加载，首先执行类的加载，加载完成后再为对象分配空间、初始化等。

1. 首先校验当前类是否被加载，如果没有加载则执行类加载
   1. 加载：就是从字节码加载成二进制流的过程；
   2. 验证：当加载完成之后，需要校验 Class 文件是否符合虚拟机规范；
   3. 准备：为静态变量、常量赋默认值；
   4. 解析：把常量池中符号引用替换为直接引用的过程；
   5. 初始化：执行static代码块进行初始化，如果存在父类，先对父类进行初始化。（**ps：*静态代码块是绝对线程安全的，只能隐式被java虚拟机在类加载过程中初始化调用！ **）
2. 对象分配内存空间和初始化过程
   1. 为对象分配合适大小的内存空间；
   2. 为实例变量赋默认值；
   3. 设置对象的头信息，对象 hash 码、GC 分代年龄、元数据信息等；
   4. 执行构造函数初始化。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIUCyy2VR6ZlqTx2Nr5muXb3kjsLYTVDbFibADcK2hict72nXb2RI9K0Wg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 2.3. 简述双亲委派模型.

类加载器自顶向下分为：

1. Bootstrap ClassLoader启动类加载器：默认会去加载JAVA_HOME/lib目录下的jar
2. Extention ClassLoader扩展类加载器：默认去加载JAVA_HOME/lib/ext目录下的jar
3. Application ClassLoader应用程序类加载器：比如我们的web应用，会加载web程序中ClassPath下的类
4. User ClassLoader用户自定义类加载器：由用户自己定义

当我们在加载类的时候，首先都会向上询问自己的父加载器是否已经加载，如果没有则依次向上询问，如果没有加载，则从上到下依次尝试是否能加载当前类，直到加载成功。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIhXK8icwZjLzVpbmwghicmyhrcx4TXWjdTVZ8ONaxrND9HLkFdNkoTgZQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

#### 2.4. 知道哪些垃圾回收算法？

- 标记-清除

统一标记出需要回收等对象，标记完成之后统一回收所有被标记的对象，而由于标记过程需要遍历所有的 GC ROOT，清除的过程也要遍历堆中所有的对象，所以标记-清除算法的效率低下，同时也会带来内存碎片的问题。

- 复制算法

为了解决性能问题，产生了复制算法，它将内存分为大小相等的两块区域，每次使用其中的一块，当一块内存使用完之后，将还存活的对象拷贝到另一块内存区域中，然后把当前内存清空，这样性能和内存碎片的问题得以解决。

因此，诞生了我们现在的常见的年轻代+老年代的内存结构：Eden+S0+S1组成，因为根据研究显示，大部分对象都是朝生夕死，所以实际上存活的对象并不是很多，完全不需要用到一半内存浪费，所以默认的比例是8:1:1。

如果最后未使用的Survivor放不下存活的对象，这些对象就进入Old老年代了。这也是为什么要分为Eden区和2个Survior区的原因。

- 标记-整理

针对老年代再用复制算法显然不合适，因为进入老年代的对象都存活率比较高了，这时候再频繁的复制对性能影响就比较大，而且也不会再有另外的空间进行兜底。所以针对老年代的特点，通过标记-整理算法，标记出所有的存活对象，让所有存活的对象都向一端移动，然后清理掉边界以外的内存空间。

#### 2.5. 那么什么是GC ROOT？有哪些GC ROOT？

对于标记算法，如何标记一个对象是否存活？简单的通过引用计数法，给对象设置一个引用计数器，每当有一个地方引用他，就给计数器+1，反之则计数器-1，但是这个简单的算法无法解决循环引用的问题。

Java通过可达性分析算法来达到标记存活对象的目的，定义一系列的GC ROOT为起点，从起点开始向下开始搜索，搜索走过的路径称为引用链，当一个对象到GC ROOT没有任何引用链相连的话，则对象可以判定是可以被回收的。

而可以作为GC ROOT的对象包括：

1. 栈中引用的对象；
2. 静态变量、常量引用的对象；
3. 本地方法栈native方法引用的对象；

#### 2.6. 垃圾回收器了解吗？年轻代和老年代都有哪些垃圾回收器?

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIiaibccybJicW4m2ibAf9lLJNiaUzRC7BxcbwwI1bcuY3LiaTap9zaKebibJjg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

年轻代的垃圾收集器包含有Serial、ParNew、Parallell，老年代则包括Serial Old老年代版本、CMS、Parallel Old老年代版本和JDK11中的船新的G1收集器。

- **Serial**：单线程版本收集器，进行垃圾回收的时候会STW（Stop The World），也就是进行垃圾回收的时候其他的工作线程都必须暂停

- **ParNew**：Serial的多线程版本，用于和CMS配合使用

- **Parallel Scavenge**：可以并行收集的多线程垃圾收集器

- **Serial Old**：Serial的老年代版本，也是单线程

- **Parallel Old**：Parallel Scavenge的老年代版本

- **CMS（Concurrent Mark Sweep）**：CMS收集器是以获取最短停顿时间为目标的收集器，相对于其他的收集器STW的时间更短暂，可以并行收集是他的特点，同时他基于标记-清除算法，整个GC的过程分为4步：

  1. 初始标记：标记GC ROOT能关联到的对象，需要STW
  2. 并发标记：从GCRoots的直接关联对象开始遍历整个对象图的过程，不需要STW
  3. 重新标记：为了修正并发标记期间，因用户程序继续运作而导致标记产生改变的标记，需要STW
  4. 并发清除：清理删除掉标记阶段判断的已经死亡的对象，不需要STW

  从整个过程来看，并发标记和并发清除的耗时最长，但是不需要停止用户线程，而初始标记和重新标记的耗时较短，但是需要停止用户线程，总体而言，整个过程造成的停顿时间较短，大部分时候是可以和用户线程一起工作的。

- **G1（Garbage First）**：G1收集器是JDK9的默认垃圾收集器，而且不再区分年轻代和老年代进行回收。

- **ZGC**：针对大堆内存设计可以支持TB级别的堆，ZGC非常高效，能够做到10ms以下的回收停顿时间

#### 2.7. G1的原理

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIu1KwEcXMxlPbymIicIxbNOWpiav0a4kibkCgaz447ia1naa3EwefOUoe6g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

G1作为JDK9之后的服务端默认收集器，且不再区分年轻代和老年代进行垃圾回收，他把内存划分为多个Region，每个Region的大小可以通过-XX：G1HeapRegionSize设置，大小为1~32M，对于大对象的存储则衍生出Humongous的概念，超过Region大小一半的对象会被认为是大对象，而超过整个Region大小的对象被认为是超级大对象，将会被存储在连续的N个Humongous Region中，G1在进行回收的时候会在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间优先回收收益最大的Region。G1的回收过程分为以下四个步骤：

1. 初始标记：标记GC ROOT能关联到的对象，需要STW
2. 并发标记：从GCRoots的直接关联对象开始遍历整个对象图的过程，扫描完成后还会重新处理并发标记过程中产生变动的对象
3. 最终标记：短暂暂停用户线程，再处理一次，需要STW
4. 筛选回收：更新Region的统计数据，对每个Region的回收价值和成本排序，根据用户设置的停顿时间制定回收计划。再把需要回收的Region中存活对象复制到空的Region，同时清理旧的Region。需要STW

总的来说除了并发标记之外，其他几个过程也还是需要短暂的STW，G1的目标是在停顿和延迟可控的情况下尽可能提高吞吐量。

#### 2.8. 什么时候会触发YGC和FGC？对象什么时候会进入老年代？

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIXa1JZZ3lzh5GpljeFmBp9IjE2qMa5iaNZbee1fibzSvkJtl97abxIHag/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

当一个新的对象来申请内存空间的时候，如果Eden区无法满足内存分配需求，则触发YGC，使用中的Survivor区和Eden区存活对象送到未使用的Survivor区，如果YGC之后还是没有足够空间，则直接进入老年代分配，如果老年代也无法分配空间，触发FGC，FGC之后还是放不下则报出OOM异常。

此外，还有一种动态年龄的判断机制，不需要等到MaxTenuringThreshold就能晋升老年代。如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。

#### 2.9. 频繁FullGC怎么排查？

发生FGC有可能是内存分配不合理，比如Eden区太小，导致对象频繁进入老年代，这时候通过启动参数配置就能看出来，另外有可能就是存在内存泄露，可以通过以下的步骤进行排查：

1. jstat -gcutil或者查看gc.log日志，查看内存回收情况

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuItDPgQsNbficMlvhh6kMYkrTzYrA9UyehPw7bjvoAFicCJZgez01AMmhg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

S0 S1 分别代表两个Survivor区占比

E代表Eden区占比，图中可以看到使用78%

O代表老年代，M代表元空间，YGC发生54次，YGCT代表YGC累计耗时，GCT代表GC累计耗时。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIEw6ltlU85ic71ibQjZC0HZ5kBs3jEccyZibILpUTO2FaibX2a3ibibPzhE9w/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

[GC [FGC 开头代表垃圾回收的类型

PSYoungGen: 6130K->6130K(9216K)] 12274K->14330K(19456K), 0.0034895 secs代表YGC前后内存使用情况

Times: user=0.02 sys=0.00, real=0.00 secs，user表示用户态消耗的CPU时间，sys表示内核态消耗的CPU时间，real表示各种墙时钟的等待时间

这两张图只是举例并没有关联关系，比如你从图里面看能到是否进行FGC，FGC的时间花费多长，GC后老年代，年轻代内存是否有减少，得到一些初步的情况来做出判断。

2. dump出内存文件在具体分析，比如通过jmap命令jmap -dump:format=b,file=dumpfile pid，导出之后再通过**Eclipse Memory Analyzer**等工具进行分析，定位到代码，修复

**ps：CPU飙高，同时FGC怎么办？办法比较类似：**

1. 找到当前进程的pid，top -p pid -H 查看资源占用，找到线程
2. printf “%x\n” pid，把线程pid转为16进制，比如0x32d
3. jstack pid|grep -A 10 0x32d查看线程的堆栈日志，还找不到问题继续
4. dump出内存文件用MAT等工具进行分析，定位到代码，修复

#### 2.10. JVM调优有什么经验吗？

所有的调优的目的都是为了用更小的硬件成本达到更高的吞吐，JVM的调优也是一样，通过对垃圾收集器和内存分配的调优达到性能的最佳。

- **几个主要的参数含义**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIURPJpeCMd0m4KRa2qvL6rMEXchRkgdelvy5m1icKQTYXv8XahTTeJgQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

1. **-Xms** 设置初始堆的大小，-Xmx设置最大堆的大小
2. **-XX:NewSize** 年轻代大小，**-XX:MaxNewSize** 年轻代最大值，**-Xmn**则是相当于同时配置 **-XX:NewSize** 和 **-XX:MaxNewSize** 为一样的值
3. **-XX:NewRatio** 设置年轻代和年老代的比值，如果为3，表示年轻代与老年代比值为1:3，默认值为2
4. **-XX:SurvivorRatio** 年轻代和两个Survivor的比值，默认8，代表比值为8:1:1
5. **-XX:PretenureSizeThreshold** 当创建的对象超过指定大小时，直接把对象分配在老年代。
6. **-XX:MaxTenuringThreshold** 设定对象在Survivor复制的最大年龄阈值，超过阈值转移到老年代
7. **-XX:MaxDirectMemorySize** 当Direct ByteBuffer分配的堆外内存到达指定大小后，即触发Full GC

- **调优**

1. 为了打印日志方便排查问题最好开启GC日志，开启GC日志对性能影响微乎其微，但是能帮助我们快速排查定位问题。

   -XX:+PrintGCTimeStamps  -XX:+PrintGCDetails  -Xloggc:gc.log

2. 一般设置-Xms=-Xmx，这样可以获得固定大小的堆内存，减少GC的次数和耗时，可以使得堆相对稳定

3. -XX:+HeapDumpOnOutOfMemoryError让JVM在发生内存溢出的时候自动生成内存快照，方便排查问题

4. -Xmn设置新生代的大小，太小会增加YGC，太大会减小老年代大小，一般设置为整个堆的1/4到1/3

5. 设置-XX:+DisableExplicitGC禁止系统System.gc()，防止手动误触发FGC造成问题

#### 2.11. 哪些场景会产生OOM？怎么解决？

- **堆内存溢出**

堆内存溢出太常见，大部分人都应该能想得到这一点，堆内存用来存储对象实例，我们只要不停的创建对象，并且保证GC Roots和对象之间有可达路径避免垃圾回收，那么在对象数量超过最大堆的大小限制后很快就能出现这个异常。

写一段代码测试一下，设置堆内存大小2M。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnhSwX86MIv3De7TibtlcepRJvibibGh3h8ehACmj3LBRXK3354iaUAovy1uyY7PAPMmIUlPloVribpFGw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

```java
public class HeapOOM {
    public static void main(String[] args) {
        List<HeapOOM> list = new ArrayList<>();
        while (true) {
            list.add(new HeapOOM());
        }
    }
}
```

运行代码，很快能看见OOM异常出现，这里的提示是*Java heap space*堆内存溢出。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnhSwX86MIv3De7TibtlcepRCUsiaUicNx6IOqzogr2LHvYdrLTVbDjbmujXouezFksHvwIcA0KYZRqg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

一般的排查方式可以通过设置-XX: +HeapDumpOnOutOfMemoryError在发生异常时dump出当前的内存转储快照来分析，分析可以使用Eclipse Memory Analyzer(MAT)来分析，独立文件可以在官网下载。

另外如果使用的是IDEA的话，可以使用商业版JProfiler或者开源版本的JVM-Profiler，此外IDEA2018版本之后内置了分析工具，包括Flame Graph(火焰图)和Call Tree(调用树)功能。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnhSwX86MIv3De7TibtlcepR8YiarUWmag8ECmR8PgIL2eHt5XZ0QJicpjEic3v13p3ZA0HE1fQ1ZCB8A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnhSwX86MIv3De7TibtlcepRl8SDyp4jcRFiaCjiaH7lgibqnUKlJz5hFvVu3Z6WxRswl6syHScdwibgxA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- **方法区(运行时常量池)和元空间溢出**

方法区和堆一样，是线程共享的区域，包含Class文件信息、运行时常量池、常量池，运行时常量池和常量池的主要区别是具备动态性，也就是不一定非要是在Class文件中的常量池中的内容才能进入运行时常量池，运行期间也可以可以将新的常量放入池中，比如String的intern()方法。

我们写一段代码验证一下String.intern()，同时我们设置-XX:MetaspaceSize=50m -XX:MaxMetaspaceSize=50m 元空间大小。由于我使用的是1.8版本的JDK，而1.8版本之前方法区存在于永久代(PermGen)，1.8之后取消了永久代的概念，转为元空间(Metaspace)，如果是之前版本可以设置PermSize MaxPermSize永久代的大小。

```java
private static String str = "test";
    public static void main(String[] args) {
        List<String> list = new ArrayList<>();
        while (true){
            String str2 = str + str;
            str = str2;
            list.add(str.intern());
        }
}
```

运行代码，会发现代码报错。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnhSwX86MIv3De7TibtlcepRUWN7iaEXfribwWoy0yGcm14l69gfCw2L3ZT7wiaHAk88SQOKQuhtEticqg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

再次修改配置，去除元空间限制，修改堆内存大小-Xms20m -Xmx20m，可以看见堆内存报错。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnhSwX86MIv3De7TibtlcepR3KHTFYOj2KIuqenht8tMU4cPlEeq59ZfPN8BU9PDzYlPkKW69F2C0A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这是为什么呢？intern()本身是一个native方法，它的作用是：如果字符串常量池中已经包含一个等 于此String对象的字符串，则返回代表池中这个字符串的String对象;否则，将此String对象包含的字符串添加到常量池中，并且返回String对象的引用。

而在1.7版本之后，字符串常量池已经转移到堆区，所以会报出堆内存溢出的错误，如果1.7之前版本的话会看见PermGen space的报错。

- **直接内存溢出**

直接内存并不是虚拟机运行时数据区域的一部分，并且不受堆内存的限制，但是受到机器内存大小的限制。常见的比如在NIO中可以使用native函数直接分配堆外内存就容易导致OOM的问题。

直接内存大小可以通过-XX:MaxDirectMemorySize指定，如果不指定，则默认与Java 堆最大值-Xmx一样。

由直接内存导致的内存溢出，一个明显的特征是在Dump文件中不会看见明显的异常，如果发现OOM之后Dump文件很小，而程序中又直接或间接使用了NIO，那就可以考虑检查一下是不是这方面的原因。

- **栈内存溢出**

栈是线程私有，它的生命周期和线程相同。每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息，方法调用的过程就是栈帧入栈和出栈的过程。

在java虚拟机规范中，对虚拟机栈定义了两种异常：

1. 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常
2. 如果虚拟机栈可以动态扩展，并且扩展时无法申请到足够的内存，抛出OutOfMemoryError异常

先写一段代码测试一下，设置-Xss160k，-Xss代表每个线程的栈内存大小

```java
public class StackOOM {
    private int length = 1;

    public void stackTest() {
        System.out.println("stack lenght=" + length);
        length++;
        stackTest();
    }

    public static void main(String[] args) {
        StackOOM test = new StackOOM();
        test.stackTest();
    }
}
```

测试发现，单线程下无论怎么设置参数都是StackOverflow异常。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnhSwX86MIv3De7TibtlcepRPLrPkrWwhEWzsyjtD1O1VFsP4jqxGYkmv1Azx9gsBNeic6LLp1joPWw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

尝试把代码修改为多线程，调整-Xss2m，因为为每个线程分配的内存越大，栈空间可容纳的线程数量越少，越容易产生内存溢出。反之，如果内存不够的情况，可以调小该参数来达到支撑更多线程的目的。

```java
public class StackOOM {
    private void dontStop() {
        while (true) {
        }
    }

    public void stackLeakByThread() {
        while (true) {
            new Thread(() -> dontStop()).start();
        }
    }

    public static void main(String[] args) throws Throwable {
        StackOOM stackOOM = new StackOOM();
        stackOOM.stackLeakByThread();
    }
}
```

----

## 3. 常用框架

### 3.1. Spring

#### 3.1.1. Spring中用到了哪些设计模式？

- `单例模式`：Spring 中的 Bean 默认情况下都是单例的
- `工厂模式`：工厂模式主要是通过 BeanFactory 和 ApplicationContext 来生产 Bean 对象。
- `代理模式`：最常见的 AOP 的实现方式就是通过代理来实现，Spring主要是使用 JDK 动态代理和 CGLIB 代理。
- `模板方法模式`：主要是一些对数据库操作的类用到，比如 JdbcTemplate、JpaTemplate，因为查询数据库的建立连接、执行查询、关闭连接几个过程，非常适用于模板方法。

#### 3.1.2. 简述对 IOC 和 AOP 的理解及实现原理

IOC 叫做控制反转，指的是通过Spring来管理对象的创建、配置和生命周期，这样相当于把控制权交给了Spring，不需要人工来管理对象之间复杂的依赖关系，这样做的好处就是解耦。在Spring里面，主要提供了 BeanFactory 和 ApplicationContext 两种 IOC 容器，通过他们来实现对 Bean 的管理。

AOP 叫做面向切面编程，他是一个编程范式，目的就是提高代码的模块性。Srping AOP 基于动态代理的方式实现，如果是实现了接口的话就会使用 JDK 动态代理，反之则使用 CGLIB 代理，Spring中 AOP 的应用主要体现在 事务、日志、异常处理等方面，通过在代码的前后做一些增强处理，可以实现对业务逻辑的隔离，提高代码的模块化能力，同时也是解耦。Spring主要提供了 Aspect 切面、JoinPoint 连接点、PointCut 切入点、Advice 增强等实现方式

#### 3.1.3. JDK 动态代理和 CGLIB代理有什么区别

JDK 动态代理主要是针对类实现了某个接口，AOP 则会使用 JDK 动态代理。他基于反射的机制实现，生成一个实现同样接口的一个代理类，然后通过重写方法的方式，实现对代码的增强。

而如果某个类没有实现接口，AOP 则会使用 CGLIB 代理。他的底层原理是基于 asm 第三方框架，通过修改字节码生成成成一个子类，然后重写父类的方法，实现对代码的增强。

#### 3.1.4. Spring AOP 和 AspectJ AOP 有什么区别？

Spring AOP 基于动态代理实现，属于运行时增强。

AspectJ 则属于编译时增强，主要有3种方式：

1. 编译时织入：指的是增强的代码和源代码我们都有，直接使用 AspectJ 编译器编译就行了，编译之后生成一个新的类，他也会作为一个正常的 Java 类装载到JVM。
2. 编译后织入：指的是代码已经被编译成 class 文件或者已经打成 jar 包，这时候要增强的话，就是编译后织入，比如你依赖了第三方的类库，又想对他增强的话，就可以通过这种方式。
3. 加载时织入：指的是在 JVM 加载类的时候进行织入。

总结下来的话，就是 Spring AOP 只能在运行时织入，不需要单独编译，性能相比 AspectJ 编译织入的方式慢，而 AspectJ 只支持编译前后和类加载时织入，性能更好，功能更加强大。

#### 3.1.5. Factory Bean 和 Bean Factory 有什么区别？

BeanFactory 是 Bean 的工厂， ApplicationContext 的父类，IOC 容器的核心，负责生产和管理 Bean 对象。

FactoryBean 是 Bean，可以通过实现 FactoryBean 接口定制实例化 Bean 的逻辑，通过代理一个Bean对象，对方法前后做一些操作。

#### 3.1.6. 简述Spring Bean 的生命周期

SpringBean 生命周期简单概括为4个阶段：

1. 实例化，创建一个Bean对象

2. 填充属性，为属性赋值

3. 初始化

4. - 如果实现了`xxxAware`接口，通过不同类型的Aware接口拿到Spring容器的资源
   - 如果实现了BeanPostProcessor接口，则会回调该接口的`postProcessBeforeInitialzation`和`postProcessAfterInitialization`方法
   - 如果配置了`init-method`方法，则会执行`init-method`配置的方法

5. 销毁

6. - 容器关闭后，如果Bean实现了`DisposableBean`接口，则会回调该接口的`destroy`方法
   - 如果配置了`destroy-method`方法，则会执行`destroy-method`配置的方法

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnmFsqZZ4gkrIRbV5o351H2AzW6WIZjiaXWE6LUS5J66vgqhicU60FNxIf0V0mv8QqssYniaFBoFibraw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 3.1.7. Spring如何解决循环依赖？

首先，Spring 解决循环依赖有两个前提条件：

1. 不全是构造器方式的循环依赖
2. 必须是单例

基于上面的问题，我们知道Bean的生命周期，本质上解决循环依赖的问题就是三级缓存，通过三级缓存提前拿到未初始化的对象。

第一级缓存：用来保存实例化、初始化都完成的对象

第二级缓存：用来保存实例化完成，但是未初始化完成的对象

第三级缓存：用来保存一个对象工厂，提供一个匿名内部类，用于创建二级缓存中的对象

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnmFsqZZ4gkrIRbV5o351H2AKQpf8yvnt5PXLsbCR8bLyMGRDEAslaMMl3AhGJq8bkMUNETTh5qpQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

假设一个简单的循环依赖场景，A、B互相依赖。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnmFsqZZ4gkrIRbV5o351H2MNTicM1Yr2ZicnqkgNZky17S90C9icBc9yHzIowluMykeHibvhNsOTkia0Q/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

A对象的创建过程：

1. 创建对象A，实例化的时候把A对象工厂放入三级缓存
2. A注入属性时，发现依赖B，转而去实例化B
3. 同样创建对象B，注入属性时发现依赖A，一次从一级到三级缓存查询A，从三级缓存通过对象工厂拿到A，把A放入二级缓存，同时删除三级缓存中的A，此时，B已经实例化并且初始化完成，把B放入一级缓存。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnmFsqZZ4gkrIRbV5o351H2AIXA8Ic8iaSIBst74uO1cib8wrbAfQpc3icONdicnK8yvialmlLJicUEuWXg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

4. 接着继续创建A，顺利从一级缓存拿到实例化且初始化完成的B对象，A对象创建也完成，删除二级缓存中的A，同时把A放入一级缓存

5. 最后，一级缓存中保存着实例化、初始化都完成的A、B对象

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnmFsqZZ4gkrIRbV5o351H24oPiaNGtpjbUhSxW4HNlPqMEFg10eaLU0V7gfrFmHJRv25pwic9XS7JQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

因此，由于把实例化和初始化的流程分开了，所以如果都是用构造器的话，就没法分离这个操作，所以都是构造器的话就无法解决循环依赖的问题了。

#### 3.1.8. 为什么要三级缓存？二级缓存行不行？

不可以，主要是为了生成代理对象。

因为三级缓存中放的是生成具体对象的匿名内部类，他可以生成代理对象，也可以是普通的实例对象。

使用三级缓存主要是为了保证不管什么时候使用的都是一个对象。

假设只有二级缓存的情况，往二级缓存中放的显示一个普通的Bean对象，`BeanPostProcessor`去生成代理对象之后，覆盖掉二级缓存中的普通Bean对象，那么多线程环境下可能取到的对象就不一致了。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnmFsqZZ4gkrIRbV5o351H2tDZJooDFwPAn5JMKHpeLrLDtgkItbZtDpWf9cBVLXFWiaqSO2TYIrEQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 3.1.9. 简述 Spring 事物传播机制。

1. **PROPAGATION_REQUIRED**：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，这也是通常我们的默认选择。
2. **PROPAGATION_REQUIRES_NEW**：创建新事务，无论当前存不存在事务，都创建新事务。
3. **PROPAGATION_NESTED**：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按REQUIRED属性执行。
4. **PROPAGATION_NOT_SUPPORTED**：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
5. **PROPAGATION_NEVER**：以非事务方式执行，如果当前存在事务，则抛出异常。
6. **PROPAGATION_MANDATORY**：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。
7. **PROPAGATION_SUPPORTS**：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。

#### 3.1.10. 简述 Spring 事务实现原理； 注解失效场景.

**事务实现原理**

1. 划分处理单元，由于spring解决的问题是对单个数据库进行局部事务处理的，具体的实现首相用spring中的IOC划分了事务处理单元。并且将对事务的各种配置放到了ioc容器中（设置事务管理器，设置事务的传播特性及隔离机制）。
2.  AOP拦截需要进行事务处理的类，Spring事务处理模块是通过AOP功能来实现声明式事务处理的，具体操作（比如事务实行的配置和读取，事务对象的抽象），用TransactionProxyFactoryBean接口来使用AOP功能，生成proxy代理对象，通过TransactionInterceptor完成对代理方法的拦截，将事务处理的功能编织到拦截的方法中。读取ioc容器事务配置属性，转化为spring事务处理需要的内部数据结构（TransactionAttributeSourceAdvisor），转化为TransactionAttribute表示的数据对象。
3. 对事物处理实现（事务的生成、提交、回滚、挂起）spring委托给具体的事务处理器实现。实现了一个抽象和适配。适配的具体事务处理器：DataSource数据源支持、hibernate数据源事务处理支持、JDO数据源事务处理支持，JPA、JTA数据源事务处理支持。这些支持都是通过设计PlatformTransactionManager、AbstractPlatforTransaction一系列事务处理的支持。 为常用数据源支持提供了一系列的TransactionManager。
4. 结合PlatformTransactionManager实现了TransactionInterception接口，让其与TransactionProxyFactoryBean结合起来，形成一个Spring声明式事务处理的设计体系

**注解失效场景**

1. **@Transactional 应用在非 public 修饰的方法上**：在在Spring AOP 代理时，事务拦截器在目标方法执行前后进行拦截并且会检查目标方法的修饰符是否为 public，不是 public 则不会获取 @Transactional 的属性配置信息。
2. **同一个类中方法调用，导致 @Transactional 失效**：这是由于使用`Spring AOP`代理造成的，因为只有当事务方法被当前类以外的代码调用时，才会由`Spring`生成的代理对象来管理。同一个累中方法调用会导致代理失效。此问题可以通过注入自身或者使用AopContext.*currentProxy*() 获取代理对象来解决
3. **异常被捕获导致 @Transactional 失效**：

```java
@Transactional(rollbackFor = RuntimeException.class)
public void a() {
  try {
    b();
  } catch (Exception e) {
    e.printStackTrace();
  }
  // ... 提交事务
}

@Transactional(rollbackFor = RuntimeException.class)
public void b() throws Exception {
  // ... 执行事务代码抛出了异常
}
```

```java
org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only
```

因为当`ServiceB`中抛出了一个异常以后，`ServiceB`标识当前事务需要`rollback`。但是`ServiceA`中由于手动的捕获这个异常并进行处理，`ServiceA`认为当前事务应该正常`commit`。此时就出现了前后不一致，也就是因为这样，抛出了前面的`UnexpectedRollbackException`异常。

#### 3.1.11. Spring 通知类型及使用场景.

1. @Before（前置通知）
2. @AfterReturning（后置通知）：记录日志
3. @Around（环绕通知）：控制事务
4. @AfterThrowing（异常通知）：异常处理，控制事务
5. @After（最终通知）：记录日志

### 3.2. SpringBoot

#### 3.2.1. 简述 SpringBoot 的启动流程.

1. 通过 `SpringFactoriesLoader` 加载 `META-INF/spring.factories` 文件，获取并创建 `SpringApplicationRunListener` 对象
2. 然后由 `SpringApplicationRunListener` 来发出 starting 消息
3. 创建参数，并配置当前 SpringBoot 应用将要使用的 Environment
4. 完成之后，依然由 `SpringApplicationRunListener` 来发出 environmentPrepared 消息
5. 创建 `ApplicationContext`
6. 初始化 `ApplicationContext`，并设置 Environment，加载相关配置等
7. 由 `SpringApplicationRunListener` 来发出 `contextPrepared` 消息，告知SpringBoot 应用使用的 `ApplicationContext` 已准备OK
8. 将各种 beans 装载入 `ApplicationContext`，继续由 `SpringApplicationRunListener` 来发出 contextLoaded 消息，告知 SpringBoot 应用使用的 `ApplicationContext` 已装填OK
9. refresh ApplicationContext，完成IoC容器可用的最后一步
10. 由 `SpringApplicationRunListener` 来发出 started 消息
11. 完成最终的程序的启动
12. 由 `SpringApplicationRunListener` 来发出 running 消息，告知程序已运行起来了

#### 3.2.2. SpringBoot 的核心注解.

@SpringBootApplication是SpringBoot最核心的注解，它是一个组合注解，包含了@SpringBootConfiguration、@EnableAutoConfiguration和@ComponentScan三个注解

- @SpringBootConfiguration：是对@Configuration进行了封装命名，@Configuration是Spring的注解，标识一个可以被组件扫描器扫描到的配置类

- @EnableAutoConfiguration：是一个组合注解
  - @AutoConfigurationPackage：通过@Import注解导入了两个类Registrar
  - 通过@Import导入AutoConfigurationImportSelector类
  - AutoConfigurationImportSelector：查找classpath下所有jar包中的META-INFO/spring.factories中EnableAutoConfiguration对应的属性，然后根据条件进行筛选（需要自动配置的类上都有条件注解比如@ConditionOnClass表示类路径中存在某个类，@ConditionOnBean表示容器中存在某个bean）

- @ComponentScan：自动扫描并加载组件，默认从声明@ComponentScan所在类的package进行扫描

#### 3.2.3. SpringBoot Starter 的工作原理.

1. Spring Boot 在启动时会去依赖的 Starter 包中寻找 resources/META-INF/spring.factories 文件，然后根据文件中配置的 Jar 包去扫描项目所依赖的 Jar 包。
2. 根据 spring.factories 配置加载 AutoConfigure 类
3. 根据 @Conditional 注解的条件，进行自动配置并将 Bean 注入 Spring Context

总结一下，其实就是 Spring Boot 在启动的时候，按照约定去读取 Spring Boot Starter 的配置信息，再根据配置信息对资源进行初始化，并注入到 Spring 容器中。这样 Spring Boot 启动完毕后，就已经准备好了一切资源，使用过程中直接注入对应 Bean 资源即可。

### 3.3. SpringMVC

#### 3.3.1. 简述SpringMVC请求流程

1. spring mvc将所有的请求都提交给DispatcherServlet,它会委托应用系统的其他模块负责对请求 进行真正的处理工作
2. DispatcherServlet查询一个或多个HandlerMapping,找到处理请求的Controller.
3. DispatcherServlet请请求提交到目标Controller
4. Controller进行业务逻辑处理后，会返回一个ModelAndView
5. Dispathcher查询一个或多个ViewResolver视图解析器,找到ModelAndView对象指定的视图对象
6. 视图对象负责渲染返回给客户端。

### 3.4. SpringCloud

#### 3.4.1. Eureka注册中心

对于任何一个微服务，原则上都应该存在多个实例，并且为了支持动态扩容，一个微服务的实例的数量往往是动态变化的，所以需要引入额外的组件来管理微服务提供者的注册和发现，这个组件就是注册中心。

工作流程：

1. Eureka Server启动成功，等待服务端注册，在启动过程中如果配置了集群，集群之间定时通过Replicate同步注册表，每个Eureka Server都存在独立完整的服务注册表信息
2. Ereka Client启动时根据配置的Eureka Server的地址去注册中心注册服务
3. Eureka Client会每隔一段时间向Eureka Server发送一次心跳请求，证明客户端服务正常，进行续约
4. 当Eureka Server 90s内没有收到客户端的心跳，注册中心则认为该节点失效，会注销该实例
5. 单位时间内Eureka Server统计到有大量客户端没有上送心跳，则任务可能是网络异常，进入自我保护机制，不再剔除没有上送心跳的客户端，当客户端心跳请求恢复正常后，Eureka Server退出自我保护机制
6. 服务调用时，Eureka Client 会先从本地缓存中获取服务注册列表，如果获取不到则从注册中心刷新注册表，再同步到本地缓存
7. Eureka Client获取目标服务器信息进行调用，如果目标服务实例有多个，则会通过Ribbon进行负载均衡
8. Eureka Client关闭时会向Eureka Server发送取消请求，Eureka Server将实例从注册表中剔除

#### 3.4.2. Ribbon

当调用具体服务时，ribbon根据服务名获取到该服务的实例列表并按照一定的负载均衡策略从列表中选择一个实例，并通过RestTemplate进行请求访问。

使用 @LoadBalanced 注解开启客户端负载均衡。

负载均衡策略：

- BestAvailable：选出最小连接数server

- RoundRobinRule：轮询，超过10次获取到的server都不可用则返回一个空

- RandomRule：随机选择，如果获取不到server则一直循环随机

- RetryRule：可以对其它策略进行重试，默认使用轮询

- WeightedResponseTimeRule：根据响应时间加权，响应时间越短权重越大

- AvailabilityFilteringRule：剔除因为读失败或者连接超过最大限制导致熔断的Server，在剩下的Server中进行轮询

#### 3.4..3. Feign

Feign是在Ribbon的基础上进行了改进，用起来更加方便，只需要顶一个接口然后添加@FeignClient注解并指定服务名称然后把调用的服务抽象成一个接口即可。

Ribbon和Feign的区别：

- 启动类使用注解不同：Ribbon使用@RibbonClient，Feign使用的是EnableFeignClients

- 服务指定位置不同：Ribbon是在@RibbonClient注解上声明，Feign则是在接口中使用@FeignClient指定

- 调用方式不同：Ribbon需要自己构建http请求，然后使用RestTemplate发送给其它服务，步骤相对比较繁琐，Feign只需要将调用其它服务的接口定义成抽象方法即可

#### 3.4.4. Hystrix熔断器

在分布式系统，我们一定会依赖各种服务，那么这些个服务一定会出现失败的情况，就会导致雪崩，Hystrix就是这样的一个工具，防雪崩利器，它具有服务降级，服务熔断，服务隔离，监控等一些防止雪崩的技术。

- 服务雪崩的原因：
  - 单个服务的代码存在bug. 
  - 请求访问量激增导致服务发生崩溃(如大型商城的枪红包，秒杀功能). 
  - 服务器的硬件故障也会导致部分服务不可用.
- Hystrix有四种防雪崩方式:
  - 服务降级：当客户端请求服务器端的时候，防止客户端一直等待，不会处理业务逻辑代码，直接返回一个友好的提示给客户端。比如接口调用失败就调用本地的方法返回一个空
  - 服务熔断：，当在一个统计时间范围内的请求失败数量达到设定值（requestVolumeThreshold）或当前的请求错误率达到设定的错误率阈值（errorThresholdPercentage）时开启断路，之后的请求直接走fallback方法，在设定时间（sleepWindowInMilliseconds）后尝试恢复。比如接口调用失败就会进入调用接口提前定义好的一个熔断的方法，返回错误信息
  - 服务隔离：就是Hystrix为隔离的服务开启一个独立的线程池，这样在高并发的情况下不会影响其他服务。隔离服务之间相互影响
  - 服务监控：在服务发生调用时,会将每秒请求数、成功请求数等运行指标记录下来。

#### 3.4.5. Zuul网关

Zuul是对SpringCloud提供的成熟对的路由方案，他会根据请求的路径不同，网关会定位到指定的微服务，并代理请求到不同的微服务接口，他对外隐蔽了微服务的真正接口地址。 三个重要概念：动态路由表，路由定位，反向代理：

- 动态路由表：Zuul支持Eureka路由，手动配置路由，这俩种都支持自动更新
- 路由定位：根据请求路径，Zuul有自己的一套定位服务规则以及路由表达式匹配
- 反向代理：客户端请求到路由网关，网关受理之后，在对目标发送请求，拿到响应之后在 给客户端

#### 3.4.6 配置中心

配置中心的作用是动态变更配置信息而不必重新部署项目。

### 3.5. Mybatis

#### 3.5.1. MyBatis工作流程

1. 加载配置并初始化，将配置封装到Configuration对象中，其中sql加载成一个个mappedStatement对象,并存放到HashMap（key为namespace.id，value为mappedStatement对象）
2. 配置加载结束后会build一个SqlSessionFactory对象用来创建SqlSession
3. 执行sql
   - 通过SqlSessionFactory的openSession()方法获取一个DefaultSqlSession对象
   - sqlSession会通过getMpper()方法获取mapper的代理类（通过MapperProxyFactory生成）
   - mapper代理类会调用sqlSession的CRUD方法，最终通过Excutor来执行jdbc代码然后返回结果集

#### 3.5.2. XML文件和Dao接口对应，Dao接口的工作原理是什么？参数不同时是否能重载？

- 通过MapperProxy动态生成Mapper的实现类，然后再执行JDBC代码

- 不能重载，mybatis的sql会被封装成MappedStatement对象中然后存放到HashMap中，Map的key是sql的namespace.id，value就是sql，会报重复错误。

#### 3.5.3. Mybatis如果进行分页？分页原理是什么？简述Mybatis插件原理？如何编写一个插件？

**如何分页**

在mysql中，limit m,n用于限制select语句返回的条数，m表示偏移量，n表示返回行数的最大值，也就是从第m条记录开始最多返回n条记录。也可以传入一个参数limit n 相当于limit 0,n。

**分页原理**

Mybatis可以通过传入RowBounds(offset, limit)对象来实现分页，Rowbounds是逻辑分页，查询出所有记录所有记录，然后对结果集进行处理。也可以使用PageHelper来实现分页，PageHelper.startPage(pageNum, pageSize),PageHelper是mybatis插件，通过动态代理和责任链模式对Executor类中的query方法进行拦截，然后通过limit查询分页结果

**mybatis插件原理**

就是通过动态代理和责任链模式对mybatis中的Executor、ParameterHandler、ResultSetHandler、StatementHandler进行拦截并进行一些扩展，从而达到对mybatis基本功能的增强

**编写插件**

实现mybatis的Intercepter接口，然后通过@Signature注解指定拦截的对象和拦截的方法。

#### 3.5.4. Mybatis的一级缓存、二级缓存

**一级缓存**

- 一级缓存默认开启，生命周期和SqlSession一致，就是说在一次会话中执行的所有语句都会共享这个缓存。

- 缓存内部设计采用的是HashMap来设计，key是*Statement Id + Offset + Limmit + Sql + Params*，value是对象。

- 查询时如果命中缓存，则直接返回，如果没有命中，则从数据库查询，然后再更新缓存

- 增删改操作会清空缓存

**二级缓存**

- 设置cacheEnabled为true，并在XML映射文件中配置，并且POJO对象要实现Serializable接口

- 相对于一级缓存来讲，实现了 SqlSession 之间数据的共享，能够到namespace级别，通过实现Cache接口来控制缓存

- 在分布式环境下，由于默认的缓存实现都是基于本地的，分布式环境下必然会读取到脏数据，需要使用RedisCache来实现，或者直接使用Redis来实现缓存

----

## 4. 数据库

#### 4.1. 简述 MyISAM 和 InnoDB的区别

myisam引擎是5.1版本之前的默认引擎，支持全文检索、压缩、空间函数等，但是不支持事务和行级锁，所以一般用于有大量查询少量插入的场景来使用，而且myisam不支持外键，并且索引和数据是分开存储的。

innodb是基于聚簇索引建立的，和myisam相反它支持事务、外键，并且通过MVCC来支持高并发，索引和数据存储在一起。

#### 4.2. CHAR 和 VARCHAR 的区别.

- char的长度是不可变的，比如定义char(10)存储的字符串长度是4，那么该字段的长度也是10，多余的长度会使用空格代替,而varchar的长度是4，就是说varchar可以节省空间

- 由于char的长度固定，方便数据库查询和存储，所以效率要高一些

#### 4.3. HAVING 字句和 WHERE 的区别.

- Where 是一个约束声明，使用Where来约束来之数据库的数据，Where是在结果返回之前起作用的，且Where中不能使用聚合函数。

- Having是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。

#### 4.4. MySQL的索引有哪些？聚簇索引呢和非聚簇索引有什么区别？

索引按照数据结构来说主要包含B+树和Hash索引。

假设有张表，结构如下：

```sql
create table user(
  id int(11) not null,
  age int(11) not null,
  primary key(id),
  key(age)
);
```

B+树是左小右大的顺序存储结构，节点只包含id索引列，而叶子节点包含索引列和数据，这种数据和索引在一起存储的索引方式叫做聚簇索引，一张表只能有一个聚簇索引。假设没有定义主键，InnoDB会选择一个唯一的非空索引代替，如果没有的话则会隐式定义一个主键作为聚簇索引。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485UNAyaZCiad9IZyfFcMfMt8CogYojcicbYW5QlqqrrQg9w7osRKEGUP9lw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这是主键聚簇索引存储的结构，那么非聚簇索引的结构是什么样子呢？非聚簇索引(二级索引)保存的是主键id值，这一点和myisam保存的是数据地址是不同的。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485U5M1te7Go4icEIby6ft9UXYoicNjIiaEP6tJ5OqDnAMX8Nd52uib8PXOibGg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

InnoDB和Myisam聚簇和非聚簇索引的区别

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485USVnE4tGnV2JQtwibibRib1wt5q01ibiaWibDG2d7UZwdbSJOEzIbT0U691mA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 4.5. 什么是覆盖索引和回表？

覆盖索引指的是在一次查询中，如果一个索引包含或者说覆盖所有需要查询的字段的值，我们就称之为覆盖索引，而不再需要回表查询。

而要确定一个查询是否是覆盖索引，我们只需要explain sql语句看Extra的结果是否是“Using index”即可。

以上面的user表来举例，我们再增加一个name字段，然后做一些查询试试。

```sql
explain select * from user where age=1; -- 查询的name无法从索引数据获取
explain select id,age from user where age=1; -- 可以直接从索引获取
```



#### 4.6. 锁的类型有哪些

mysql锁分为**共享锁**和**排他锁**，也叫做读锁和写锁。

读锁是共享的，可以通过lock in share mode实现，这时候只能读不能写。

写锁是排他的，它会阻塞其他的写锁和读锁。从颗粒度来区分，可以分为**表锁**和**行锁**两种。

表锁会锁定整张表并且阻塞其他用户对该表的所有读写操作，比如alter修改表结构的时候会锁表。

行锁又可以分为 **乐观锁** 和 **悲观锁**，悲观锁可以通过for update实现，乐观锁则通过版本号实现。

#### 4.7. 简述事务的基本特性和隔离级别

事务基本特性ACID分别是：

**原子性**指的是一个事务中的操作要么全部成功，要么全部失败。

**一致性**指的是数据库总是从一个一致性的状态转换到另外一个一致性的状态。比如A转账给B100块钱，假设中间sql执行过程中系统崩溃A也不会损失100块，因为事务没有提交，修改也就不会保存到数据库。

**隔离性**指的是一个事务的修改在最终提交前，对其他事务是不可见的。

**持久性**指的是一旦事务提交，所做的修改就会永久保存到数据库中。

而隔离性有4个隔离级别，分别是：

**read uncommit** 读未提交，可能会读到其他事务未提交的数据，也叫做脏读。

用户本来应该读取到id=1的用户age应该是10，结果读取到了其他事务还没有提交的事务，结果读取结果age=20，这就是脏读。

<img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485UADTzKMibJwb1picAytaqIIyWLQM0UeocSSKymzm6e8ChYlI3tVzialCicA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:150%;" />

**read commit** 读已提交，两次读取结果不一致，叫做不可重复读。

不可重复读解决了脏读的问题，他只会读取已经提交的事务。

用户开启事务读取id=1用户，查询到age=10，再次读取发现结果=20，在同一个事务里同一个查询读取到不同的结果叫做不可重复读。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485UeiaLx7HFnfbuiaTUlrib9k9117AQ2noW6Q10iaefPG3OxXSviakGjqiaTVMw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**repeatable read** 可重复复读，这是mysql的默认级别，就是每次读取结果都一样，但是有可能产生幻读。

**serializable** 串行，一般是不会使用的，他会给每一行读取的数据加锁，会导致大量超时和锁竞争的问题。

#### 4.8. MySQL 事务是如何保证 ACID 特性的？

A原子性由undo log日志保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功的sql

C一致性一般由代码层面来保证

I隔离性由MVCC来保证

D持久性由内存+redo log来保证，mysql修改数据同时在内存和redo log记录这次操作，事务提交的时候通过redo log刷盘，宕机的时候可以从redo log恢复

#### 4.9. 什么是幻读？什么是MVCC？

要说幻读，首先要了解MVCC，MVCC叫做多版本并发控制，实际上就是保存了数据在某个时间节点的快照。

我们每行数实际上隐藏了两列，创建时间版本号，过期(删除)时间版本号，每开始一个新的事务，版本号都会自动递增。

还是拿上面的user表举例子，假设我们插入两条数据，他们实际上应该长这样。

| id   | name | create_version | delete_version |
| ---- | ---- | -------------- | -------------- |
| 1    | 张三 | 1              |                |
| 2    | 李四 | 2              |                |

这时候假设小明去执行查询，此时current_version=3

这时候假设小明去执行查询，此时current_version=3

```
select * from user where id<=3;
```

同时，小红在这时候开启事务去修改id=1的记录，current_version=4

```
update user set name='张三三' where id=1;
```

执行成功后的结果是这样的

| id   | name   | create_version | delete_version |
| ---- | ------ | -------------- | -------------- |
| 1    | 张三   | 1              |                |
| 2    | 李四   | 2              |                |
| 1    | 张三三 | 4              |                |

如果这时候还有小黑在删除id=2的数据，current_version=5，执行后结果是这样的。

| id   | name   | create_version | delete_version |
| ---- | ------ | -------------- | -------------- |
| 1    | 张三   | 1              |                |
| 2    | 李四   | 2              | 5              |
| 1    | 张三三 | 4              |                |

由于MVCC的原理是查找创建版本小于或等于当前事务版本，删除版本为空或者大于当前事务版本，小明的真实的查询应该是这样

```sql
select * from user where id<=3 and create_version<=3 and (delete_version>3 or delete_version is null);
```

所以小明最后查询到的id=1的名字还是'张三'，并且id=2的记录也能查询到。这样做是 **为了保证事务读取的数据是在事务开始前就已经存在的，要么是事务自己插入或者修改的**。

明白MVCC原理，我们来说什么是幻读就简单多了。举一个常见的场景，用户注册时，我们先查询用户名是否存在，不存在就插入，假定用户名是唯一索引。

1. 小明开启事务current_version=6查询名字为'王五'的记录，发现不存在。
2. 小红开启事务current_version=7插入一条数据，结果是这样：

| id   | Name | create_version | delete_version |
| ---- | ---- | -------------- | -------------- |
| 1    | 张三 | 1              |                |
| 2    | 李四 | 2              |                |
| 3    | 王五 | 7              |                |

3. 小明执行插入名字'王五'的记录，发现唯一索引冲突，无法插入，这就是幻读。

#### 4.10. 知道什么是间隙锁吗？

间隙锁是可重复读级别下才会有的锁，结合MVCC和间隙锁可以解决幻读的问题。我们还是以user举例，假设现在user表有几条记录

| id   | Age  |
| :--- | ---- |
| 1    | 10   |
| 2    | 20   |
| 3    | 30   |

当我们执行：

```sql
begin;
select * from user where age=20 for update;

begin;
insert into user(age) values(10); #成功
insert into user(age) values(11); #失败
insert into user(age) values(20); #失败
insert into user(age) values(21); #失败
insert into user(age) values(30); #失败
```

只有10可以插入成功，那么因为表的间隙mysql自动帮我们生成了区间(左开右闭)

```sql
(negative infinity，10],(10,20],(20,30],(30,positive infinity)
```

由于20存在记录，所以(10,20]，(20,30]区间都被锁定了无法插入、删除。

如果查询21呢？就会根据21定位到(20,30)的区间(都是开区间)。

需要注意的是唯一索引是不会有间隙索引的。

#### 4.11. 分库分表如何做？

首先分库分表分为垂直和水平两个方式，一般来说我们拆分的顺序是先垂直后水平。

**垂直分库**

基于现在微服务拆分来说，都是已经做到了垂直分库了

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485Ub7GrOacc0Pr1CE9NTjg0XDyLOLhQ8A7rslyKvRW42QLTib3cjqSP1Uw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**垂直分表**

如果表字段比较多，将不常用的、数据较大的等等做拆分

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485Uk3OKhn3leSJuRg7X6tIU8LvHM0v5N5yCF2JeiagD1q19pvvliaxLteXg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**水平分表**

首先根据业务场景来决定使用什么字段作为分表字段(sharding_key)，比如我们现在日订单1000万，我们大部分的场景来源于C端，我们可以用user_id作为sharding_key，数据查询支持到最近3个月的订单，超过3个月的做归档处理，那么3个月的数据量就是9亿，可以分1024张表，那么每张表的数据大概就在100万左右。

比如用户id为100，那我们都经过hash(100)，然后对1024取模，就可以落到对应的表上了。

#### 4.12. 分表后的 id 如何保证唯一性？

因为我们主键默认都是自增的，那么分表之后的主键在不同表就肯定会有冲突了。有几个办法考虑：

1. 设定步长，比如1-1024张表我们设定1024的基础步长，这样主键落到不同的表就不会冲突了。
2. 分布式ID，自己实现一套分布式ID生成算法或者使用开源的比如雪花算法这种
3. 分表后不使用主键作为查询依据，而是每张表单独新增一个字段作为唯一主键使用，比如订单表订单号是唯一的，不管最终落在哪张表都基于订单号作为查询依据，更新也一样。

#### 4.13. 分表后非sharding_key的查询如何处理

1. 可以做一个mapping表，比如这时候商家要查询订单列表怎么办呢？不带user_id查询的话你总不能扫全表吧？所以我们可以做一个映射关系表，保存商家和用户的关系，查询的时候先通过商家查询到用户列表，再通过user_id去查询。
2. 打宽表，一般而言，商户端对数据实时性要求并不是很高，比如查询订单列表，可以把订单表同步到离线（实时）数仓，或者基于其他如es提供查询服务。
3. 数据量不是很大的话，比如后台的一些查询之类的，也可以通过多线程扫表，然后再聚合结果的方式来做。或者异步的形式也是可以的。

```java
List<Callable<List<User>>> taskList = Lists.newArrayList();
for (int shardingIndex = 0; shardingIndex < 1024; shardingIndex++) {
    taskList.add(() -> (userMapper.getProcessingAccountList(shardingIndex)));
}
List<ThirdAccountInfo> list = null;
try {
    list = taskExecutor.executeTask(taskList);
} catch (Exception e) {
    //do something
}

public class TaskExecutor {
    public <T> List<T> executeTask(Collection<? extends Callable<T>> tasks) throws Exception {
        List<T> result = Lists.newArrayList();
        List<Future<T>> futures = ExecutorUtil.invokeAll(tasks);
        for (Future<T> future : futures) {
            result.add(future.get());
        }
        return result;
    }
}
```

#### 4.14. 简述 MySQL 主从同步原理及如何解决主从延迟的问题

首先先了解mysql主从同步的原理

1. master提交完事务后，写入binlog
2. slave连接到master，获取binlog
3. master创建dump线程，推送binglog到slave
4. slave启动一个IO线程读取同步过来的master的binlog，记录到relay log中继日志中
5. slave再开启一个sql线程读取relay log事件并在slave执行，完成同步
6. slave记录自己的binglog

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485U1uHePukqQsKN6zKibICaRz1Zj3msDFIjNrFX4lkCVjYoibbib6LaU2XKw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

由于mysql默认的复制方式是异步的，主库把日志发送给从库后不关心从库是否已经处理，这样会产生一个问题就是假设主库挂了，从库处理失败了，这时候从库升为主库后，日志就丢失了。由此产生两个概念。

**全同步复制**

主库写入binlog后强制同步日志到从库，所有的从库都执行完成后才返回给客户端，但是很显然这个方式的话性能会受到严重影响。

**半同步复制**

和全同步不同的是，半同步复制的逻辑是这样，从库写入日志成功后返回ACK确认给主库，主库收到至少一个从库的确认就认为写操作完成。

**主从延迟**

这个问题貌似真的是个无解的问题，只能是说自己来判断了，需要走主库的强制走主库查询。

----

## 5. 缓存

#### 5.1. 简述 Redis 的基本数据类型

1. 字符串：redis没有直接使用C语言传统的字符串表示，而是自己实现的叫做简单动态字符串SDS的抽象类型。C语言的字符串不记录自身的长度信息，而SDS则保存了长度信息，这样将获取字符串长度的时间由O(N)降低到了O(1)，同时可以避免缓冲区溢出和减少修改字符串长度时所需的内存重分配次数。
2. 链表linkedlist：redis链表是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使用到了链表来实现，每个链表的节点由一个listNode结构来表示，每个节点都有指向前置节点和后置节点的指针，同时表头节点的前置和后置节点都指向NULL。
3. 字典hashtable：用于保存键值对的抽象数据结构。redis使用hash表作为底层实现，每个字典带有两个hash表，供平时使用和rehash时使用，hash表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对hash表进行扩容或者缩容的时候，为了服务的可用性，rehash的过程不是一次性完成的，而是渐进式的。
4. 跳跃表skiplist：跳跃表是有序集合的底层实现之一，redis中在实现有序集合键和集群节点的内部结构中都是用到了跳跃表。redis跳跃表由zskiplist和zskiplistNode组成，zskiplist用于保存跳跃表信息（表头、表尾节点、长度等），zskiplistNode用于表示表跳跃节点，每个跳跃表的层高都是1-32的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。
5. 整数集合intset：用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。
6. 压缩列表ziplist：压缩列表是为节约内存而开发的顺序性数据结构，他可以包含多个节点，每个节点可以保存一个字节数组或者整数值。

基于这些基础的数据结构，redis封装了自己的对象系统，包含字符串对象string、列表对象list、哈希对象hash、集合对象set、有序集合对象zset，每种对象都用到了至少一种基础的数据结构。

redis通过encoding属性设置对象的编码形式来提升灵活性和效率，基于不同的场景redis会自动做出优化。不同对象的编码如下：

1. 字符串对象string：int整数、embstr编码的简单动态字符串、raw简单动态字符串
2. 列表对象list：ziplist、linkedlist
3. 哈希对象hash：ziplist、hashtable
4. 集合对象set：intset、hashtable
5. 有序集合对象zset：ziplist、skiplist

#### 5.2. Redis 为什么快？为什么 Redis6.0 之后又改用多线程？

redis的速度非常的快，单机的redis就可以支撑每秒10几万的并发，相对于mysql来说，性能是mysql的几十倍。速度快的原因主要有几点：

1. 完全基于内存操作
2. C语言实现，优化过的数据结构，基于几种基础的数据结构，redis做了大量的优化，性能极高
3. 使用单线程，无上下文的切换成本
4. 基于非阻塞的IO多路复用机制

redis使用多线程并非是完全摒弃单线程，redis还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。

这样做的目的是因为redis的性能瓶颈在于网络IO而非CPU，使用多线程能提升IO读写的效率，从而整体提高redis的性能。

#### 5.3. 什么是热 key？热 key 问题怎么解决？

所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key，那么这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机引发雪崩。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAot2hSYkmxjb2lppicYuBMrmRia0jLg8zCMveicIHwbnFZ3dm7xo0xzyNOuA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

针对热key的解决方案：

1. 提前把热key打散到不同的服务器，降低压力
2. 加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询

#### 5.4. 什么是缓存击穿、缓存穿透、缓存雪崩？

###### 5.4.1 缓存击穿

缓存击穿的概念就是单个key并发访问过高，过期时导致所有请求直接打到db上，这个和热key的问题比较类似，只是说的点在于过期导致请求全部打到DB上而已。

解决方案：

1. 加锁更新，比如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。
2. 将过期时间组合写在value中，通过异步的方式不断的刷新过期时间，防止此类现象。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAot15ia9NJVxN1r9QDltntLmqC5MxBBlIOOBDvnvNBiciaYXFcOut4ZD5p1g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

###### 5.4.2. 缓存穿透

缓存穿透是指查询不存在缓存中的数据，每次请求都会打到DB，就像缓存不存在一样。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAotfyfg1VfmxRiaxwqyukuox5QNiazUlicn7FJ9Anicbl8bPGf25VMYNYhKuQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

针对这个问题，加一层布隆过滤器。布隆过滤器的原理是在你存入数据的时候，会通过散列函数将它映射为一个位数组中的K个点，同时把他们置为1。

这样当用户再次来查询A，而A在布隆过滤器值为0，直接返回，就不会产生击穿请求打到DB了。

显然，使用布隆过滤器之后会有一个问题就是误判，因为它本身是一个数组，可能会有多个值落到同一个位置，那么理论上来说只要我们的数组长度够长，误判的概率就会越低，这种问题就根据实际情况来就好了。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAotwmfeKnHQeeQqYdkcqnYV61WpN3SKnJCxqpAZ1XauEAz6WyooC542KA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

###### 5.4.3. 缓存雪崩

当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上，这样可能导致整个系统的崩溃，称为雪崩。雪崩和击穿、热key的问题不太一样的是，他是指大规模的缓存都过期失效了。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAot0TVVVSI3kCN5mQIUwIU0jZeaZylKHeFRibbf473TNs9fF1Ut0Gg3rAg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

针对雪崩几个解决方案：

1. 针对不同key设置不同的过期时间，避免同时过期
2. 限流，如果redis宕机，可以限流，避免同时刻大量请求打崩DB
3. 二级缓存，同热key的方案。

#### 5.5. Redis的过期策略有哪些？

**惰性删除**

惰性删除指的是当我们查询key的时候才对key进行检测，如果已经达到过期时间，则删除。显然，他有一个缺点就是如果这些过期的key没有被访问，那么他就一直无法被删除，而且一直占用内存。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAotTUJJNic94cee1OKFlibBEJpiazwQu2YRicbyicicpYiboFYicnDETibNddYdO7A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**定期删除**

定期删除指的是redis每隔一段时间对数据库做一次检查，删除里面的过期key。由于不可能对所有key去做轮询来删除，所以redis会每次随机取一些key去做检查和删除。

#### 5.6. 定期+惰性都没有删除过期的key怎么办？

假设redis每次定期随机查询key的时候没有删掉，这些key也没有做查询的话，就会导致这些key一直保存在redis里面无法被删除，这时候就会走到redis的内存淘汰机制。

1. volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰
2. volatile-ttl：从已设置过期时间的key中，移出将要过期的key
3. volatile-random：从已设置过期时间的key中随机选择key淘汰
4. allkeys-lru：从key中选择最近最少使用的进行淘汰
5. allkeys-random：从key中随机选择key进行淘汰
6. noeviction：当内存达到阈值的时候，新写入操作报错

#### 5.7. 持久化方式有哪些？有什么区别？

**RDB**

RDB持久化可以手动执行也可以根据配置定期执行，它的作用是将某个时间点上的数据库状态保存到RDB文件中，RDB文件是一个压缩的二进制文件，通过它可以还原某个时刻数据库的状态。由于RDB文件是保存在硬盘上的，所以即使redis崩溃或者退出，只要RDB文件存在，就可以用它来恢复还原数据库的状态。

可以通过SAVE或者BGSAVE来生成RDB文件。

SAVE命令会阻塞redis进程，直到RDB文件生成完毕，在进程阻塞期间，redis不能处理任何命令请求，这显然是不合适的。

BGSAVE则是会fork出一个子进程，然后由子进程去负责生成RDB文件，父进程还可以继续处理命令请求，不会阻塞进程。

**AOF**

AOF和RDB不同，AOF是通过保存redis服务器所执行的写命令来记录数据库状态的。

AOF通过追加、写入、同步三个步骤来实现持久化机制。

1. 当AOF持久化处于激活状态，服务器执行完写命令之后，写命令将会被追加append到aof_buf缓冲区的末尾
2. 在服务器每结束一个事件循环之前，将会调用flushAppendOnlyFile函数决定是否要将aof_buf的内容保存到AOF文件中，可以通过配置appendfsync来决定。

```shell
always ##aof_buf内容写入并同步到AOF文件
everysec ##将aof_buf中内容写入到AOF文件，如果上次同步AOF文件时间距离现在超过1秒，则再次对AOF文件进行同步
no ##将aof_buf内容写入AOF文件，但是并不对AOF文件进行同步，同步时间由操作系统决定
```

如果不设置，默认选项将会是everysec，因为always来说虽然最安全（只会丢失一次事件循环的写命令），但是性能较差，而everysec模式只不过会可能丢失1秒钟的数据，而no模式的效率和everysec相仿，但是会丢失上次同步AOF文件之后的所有写命令数据。

#### 5.8. 怎么实现Redis的高可用？

要想实现高可用，一台机器肯定是不够的，而redis要保证高可用，有2个可选方案。

**主从架构**

主从模式是最简单的实现高可用的方案，核心就是主从同步。主从同步的原理如下：

1. slave发送sync命令到master
2. master收到sync之后，执行bgsave，生成RDB全量文件
3. master把slave的写命令记录到缓存
4. bgsave执行完毕之后，发送RDB文件到slave，slave执行
5. master发送缓存中的写命令到slave，slave执行

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAotdopLgAB9KKiah8qqA71ZkztXrn885zDVCyFSnricEAPyWdo9w9lxG6icg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这里写的这个命令是sync，但是在redis2.8版本之后已经使用psync来替代sync了，原因是sync命令非常消耗系统资源，而psync的效率更高。

**哨兵**

基于主从方案的缺点还是很明显的，假设master宕机，那么就不能写入数据，那么slave也就失去了作用，整个架构就不可用了，除非你手动切换，主要原因就是因为没有自动故障转移机制。而哨兵(sentinel)的功能比单纯的主从架构全面的多了，它具备自动故障转移、集群监控、消息通知等功能。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAotgVjlOy0uURyKRueXhar16F3ndHj2sQOme4tLbAGwg4Pia5dzcucWhXA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

哨兵可以同时监视多个主从服务器，并且在被监视的master下线时，自动将某个slave提升为master，然后由新的master继续接收命令。整个过程如下：

1. 初始化sentinel，将普通的redis代码替换成sentinel专用代码
2. 初始化masters字典和服务器信息，服务器信息主要保存ip:port，并记录实例的地址和ID
3. 创建和master的两个连接，命令连接和订阅连接，并且订阅sentinel:hello频道
4. 每隔10秒向master发送info命令，获取master和它下面所有slave的当前信息
5. 当发现master有新的slave之后，sentinel和新的slave同样建立两个连接，同时每个10秒发送info命令，更新master信息
6. sentinel每隔1秒向所有服务器发送ping命令，如果某台服务器在配置的响应时间内连续返回无效回复，将会被标记为下线状态
7. 选举出领头sentinel，领头sentinel需要半数以上的sentinel同意
8. 领头sentinel从已下线的的master所有slave中挑选一个，将其转换为master
9. 让所有的slave改为从新的master复制数据
10. 将原来的master设置为新的master的从服务器，当原来master重新回复连接时，就变成了新master的从服务器

sentinel会每隔1秒向所有实例（包括主从服务器和其他sentinel）发送ping命令，并且根据回复判断是否已经下线，这种方式叫做主观下线。当判断为主观下线时，就会向其他监视的sentinel询问，如果超过半数的投票认为已经是下线状态，则会标记为客观下线状态，同时触发故障转移。

#### 5.9. 简述 Redis 集群的原理

如果说依靠哨兵可以实现redis的高可用，如果还想在支持高并发同时容纳海量的数据，那就需要redis集群。redis集群是redis提供的分布式数据存储方案，集群通过数据分片sharding来进行数据的共享，同时提供复制和故障转移的功能。

**结点**

一个redis集群由多个节点node组成，而多个node之间通过cluster meet命令来进行连接，节点的握手过程：

1. 节点A收到客户端的cluster meet命令
2. A根据收到的IP地址和端口号，向B发送一条meet消息
3. 节点B收到meet消息返回pong
4. A知道B收到了meet消息，返回一条ping消息，握手成功
5. 最后，节点A将会通过gossip协议把节点B的信息传播给集群中的其他节点，其他节点也将和B进行握手

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAot333fTiaaCA3ibxfwpnZ8VbzLkaM4cxHs23REHZVCibGUF4GdZmLNviaPYQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**槽slot**

redis通过集群分片的形式来保存数据，整个集群数据库被分为16384个slot，集群中的每个节点可以处理0-16384个slot，当数据库16384个slot都有节点在处理时，集群处于上线状态，反之只要有一个slot没有得到处理都会处理下线状态。通过cluster addslots命令可以将slot指派给对应节点处理。

slot是一个位数组，数组的长度是16384/8=2048，而数组的每一位用1表示被节点处理，0表示不处理，如图所示的话表示A节点处理0-7的slot。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAot9WNKa3CWnMYFY4JK5MKCOdcUZYmsYtpa7RNofu11gamgcRibyU14y0g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

当客户端向节点发送命令，如果刚好找到slot属于当前节点，那么节点就执行命令，反之，则会返回一个MOVED命令到客户端指引客户端转向正确的节点。（MOVED过程是自动的）

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmIwmSMLlrCHEj66HjJlAotRea7czTYia2kyQric4rkZOdnbfD7U4WHLErfu6BjU4jvTGicGZFLVTaicA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

如果增加或者移出节点，对于slot的重新分配也是非常方便的，redis提供了工具帮助实现slot的迁移，整个过程是完全在线的，不需要停止服务。

**故障转移**

如果节点A向节点B发送ping消息，节点B没有在规定的时间内响应pong，那么节点A会标记节点B为pfail疑似下线状态，同时把B的状态通过消息的形式发送给其他节点，如果超过半数以上的节点都标记B为pfail状态，B就会被标记为fail下线状态，此时将会发生故障转移，优先从复制数据较多的从节点选择一个成为主节点，并且接管下线节点的slot，整个过程和哨兵非常类似，都是基于Raft协议做选举。

#### 5.10. 简述 Redis 事务机制

redis通过MULTI、EXEC、WATCH等命令来实现事务机制，事务执行过程将一系列多个命令按照顺序一次性执行，并且在执行期间，事务不会被中断，也不会去执行客户端的其他请求，直到所有命令执行完毕。事务的执行过程如下：

1. 服务端收到客户端请求，事务以MULTI开始
2. 如果客户端正处于事务状态，则会把事务放入队列同时返回给客户端QUEUED，反之则直接执行这个命令
3. 当收到客户端EXEC命令时，WATCH命令监视整个事务中的key是否有被修改，如果有则返回空回复到客户端表示失败，否则redis会遍历整个事务队列，执行队列中保存的所有命令，最后返回结果给客户端

WATCH的机制本身是一个CAS的机制，被监视的key会被保存到一个链表中，如果某个key被修改，那么REDIS_DIRTY_CAS标志将会被打开，这时服务器会拒绝执行事务。

#### 5.11. Redis并发竞争key的解决方案

当多个系统去 set 同一个 key 时，可能本来应该先到的值后到了，导致数据版本不一致；又或者多个系统同时获取一个key，修改值之后再写回Redis，只要顺序错了，数据就错了

- 采用分布式锁 + 时间戳，抢到锁的系统把时间戳设置到 value 中，接下来如果其它系统抢到锁后发现自己的时间戳小于 value 中的时间戳，就不做更新操作
- 可以通过消息中间件进行处理，把并行读写进行串行化。

#### 5.12. 缓存一致性问题怎么解决？

**先删缓存，再更新数据库**

先删除缓存，数据库还没有更新成功，此时如果读取缓存，缓存不存在，去数据库中读取到的是旧值，缓存不一致发生。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUlFdO5Ewr8kzmib7oWwrp8Yv7iaBF9hVw97NYvO97jcBXFbCh9RDswX55IBk4GHkZ0ZYg1T8NlUrxpw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:150%;" />

**解决方案-延时双删**

延时双删的方案的思路是，为了避免更新数据库的时候，其他线程从缓存中读取不到数据，就在更新完数据库之后，再sleep一段时间，然后再次删除缓存。

sleep的时间要对业务读写缓存的时间做出评估，sleep时间大于读写缓存的时间即可。

流程如下：

1. 线程1删除缓存，然后去更新数据库
2. 线程2来读缓存，发现缓存已经被删除，所以直接从数据库中读取，这时候由于线程1还没有更新完成，所以读到的是旧值，然后把旧值写入缓存
3. 线程1，根据估算的时间，sleep，由于sleep的时间大于线程2读数据+写缓存的时间，所以缓存被再次删除
4. 如果还有其他线程来读取缓存的话，就会再次从数据库中读取到最新值

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUlFdO5Ewr8kzmib7oWwrp8Yvbiax6o64DtBCWTqMvYoeEHU4a9BSQAPfftiayBtoiaibojYewVGzQES73A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**先更新数据库，再删除缓存**

如果反过来操作，先更新数据库，再删除缓存呢？

这个就更明显的问题了，更新数据库成功，如果删除缓存失败或者还没有来得及删除，那么，其他线程从缓存中读取到的就是旧值，还是会发生不一致。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUlFdO5Ewr8kzmib7oWwrp8YvklHRwSIvP832VwCDGPFd1D5zLournIWsKLzVk0OvzvImAFQDBZRsCw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:150%;" />

**解决方案-消息队列**

先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUlFdO5Ewr8kzmib7oWwrp8YvZemne8Bs2XoAJ39oymFw2PzzEltT8Uqq5AapwbqibHA4DLlbndAPicag/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:150%;" />

这个解决方案其实问题更多。

1. 引入消息中间件之后，问题更复杂了，怎么保证消息不丢失更麻烦
2. 就算更新数据库和删除缓存都没有发生问题，消息的延迟也会带来短暂的不一致性，不过这个延迟相对来说还是可以接受的

**解决方案-进阶版消息队列**

为了解决缓存一致性的问题单独引入一个消息队列，太复杂了。

其实，一般大公司本身都会有监听binlog消息的消息队列存在，主要是为了做一些核对的工作。

这样，我们可以借助监听binlog的消息队列来做删除缓存的操作。这样做的好处是，不用你自己引入，侵入到你的业务代码中，中间件帮你做了解耦，同时，中间件的这个东西本身就保证了高可用。

当然，这样消息延迟的问题依然存在，但是相比单纯引入消息队列的做法更好一点。

而且，如果并发不是特别高的话，这种做法的实时性和一致性都还算可以接受的。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUlFdO5Ewr8kzmib7oWwrp8Yvic5QwXEFvLSibgOC0O0SA9ASpycO7JriaH3hJunV1hFFf0mqmzWv9fz4Q/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:150%;" />

**其它解决方案-设置缓存过期时间**

每次放入缓存的时候，设置一个过期时间，比如5分钟，以后的操作只修改数据库，不操作缓存，等待缓存超时后从数据库重新读取。

如果对于一致性要求不是很高的情况，可以采用这种方案。

这个方案还会有另外一个问题，就是如果数据更新的特别频繁，不一致性的问题就很大了。

在实际生产中，我们有一些活动的缓存数据是使用这种方式处理的。

因为活动并不频繁发生改变，而且对于活动来说，短暂的不一致性并不会有什么大的问题。

**为什么是删除，而不是更新缓存？**

我们以**先更新数据库，再删除缓存**来举例。

如果是更新的话，那就是**先更新数据库，再更新缓存**。

举个例子：如果数据库1小时内更新了1000次，那么缓存也要更新1000次，但是这个缓存可能在1小时内只被读取了1次，那么这1000次的更新有必要吗？

反过来，如果是删除的话，就算数据库更新了1000次，那么也只是做了1次缓存删除，只有当缓存真正被读取的时候才去数据库加载。

**总结**

首先要明确一点，缓存不是更新，而应该是删除。

删除缓存有两种方式：

1. 先删除缓存，再更新数据库。解决方案是使用延迟双删。
2. 先更新数据库，再删除缓存。解决方案是消息队列或者其他binlog同步，引入消息队列会带来更多的问题，并不推荐直接使用。

针对缓存一致性要求不是很高的场景，那么只通过设置超时时间就可以了。

其实，如果不是很高的并发，无论你选择先删缓存还是后删缓存的方式，都几乎很少能产生这种问题，但是在高并发下，应该知道怎么解决问题。

----

## 6. 消息队列

继之前的mysql夺命连环之后，我发现我这个标题被好多套用的，什么夺命zookeeper，夺命多线程一大堆，这一次，开始面试题系列MQ专题，消息队列作为日常常见的使用中间件，面试也是必问的点之一，一起来看看MQ的面试题。

#### 6.1. 你们为什么使用mq？具体的使用场景是什么？

mq的作用很简单，削峰填谷。以电商交易下单的场景来说，正向交易的过程可能涉及到创建订单、扣减库存、扣减活动预算、扣减积分等等。每个接口的耗时如果是100ms，那么理论上整个下单的链路就需要耗费400ms，这个时间显然是太长了。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxko68vujyliaj8yU46v4sdtaebPrkVMnh0KHrJftjfich9Qic8UBdSzm5iamg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

如果这些操作全部同步处理的话，首先调用链路太长影响接口性能，其次分布式事务的问题很难处理，这时候像扣减预算和积分这种对实时一致性要求没有那么高的请求，完全就可以通过mq异步的方式去处理了。同时，考虑到异步带来的不一致的问题，我们可以通过job去重试保证接口调用成功，而且一般公司都会有核对的平台，比如下单成功但是未扣减积分的这种问题可以通过核对作为兜底的处理方案。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxkocM2TfstjrBjftpCoNmF60ZtQwNh5DsFUUsz8f51HaDrgoSaibNeyXSg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

使用mq之后我们的链路变简单了，同时异步发送消息我们的整个系统的抗压能力也上升了。

#### 6.2. 那你们使用什么mq？基于什么做的选型？

我们主要调研了几个主流的mq，kafka、rabbitmq、rocketmq、activemq，选型我们主要基于以下几个点去考虑：

1. 由于我们系统的qps压力比较大，所以性能是首要考虑的要素。
2. 开发语言，由于我们的开发语言是java，主要是为了方便二次开发。
3. 对于高并发的业务场景是必须的，所以需要支持分布式架构的设计。
4. 功能全面，由于不同的业务场景，可能会用到顺序消息、事务消息等。

基于以上几个考虑，我们最终选择了RocketMQ。

|            | Kafka              | RocketMQ                     | RabbitMQ               | ActiveMQ                 |
| :--------- | :----------------- | :--------------------------- | :--------------------- | :----------------------- |
| 单机吞吐量 | 10万级             | 10万级                       | 万级                   | 万级                     |
| 开发语言   | Scala              | Java                         | Erlang                 | Java                     |
| 高可用     | 分布式架构         | 分布式架构                   | 主从架构               | 主从架构                 |
| 性能       | ms级               | ms级                         | us级                   | ms级                     |
| 功能       | 只支持主要的MQ功能 | 顺序消息、事务消息等功能完善 | 并发强、性能好、延时低 | 成熟的社区产品、文档丰富 |

#### 6.3. 你上面提到异步发送，那消息可靠性怎么保证？

消息丢失可能发生在生产者发送消息、MQ本身丢失消息、消费者丢失消息3个方面。

**生产者丢失**

生产者丢失消息的可能点在于程序发送失败抛异常了没有重试处理，或者发送的过程成功但是过程中网络闪断MQ没收到，消息就丢失了。

由于同步发送的一般不会出现这样使用方式，所以我们就不考虑同步发送的问题，我们基于异步发送的场景来说。

异步发送分为两个方式：**异步有回调和异步无回调**，无回调的方式，生产者发送完后不管结果可能就会造成消息丢失，而通过异步发送+回调通知+本地消息表的形式我们就可以做出一个解决方案。以下单的场景举例。

1. 下单后先保存本地数据和MQ消息表，这时候消息的状态是发送中，如果本地事务失败，那么下单失败，事务回滚。
2. 下单成功，直接返回客户端成功，异步发送MQ消息
3. MQ回调通知消息发送结果，对应更新数据库MQ发送状态
4. JOB轮询超过一定时间（时间根据业务配置）还未发送成功的消息去重试
5. 在监控平台配置或者JOB程序处理超过一定次数一直发送不成功的消息，告警，人工介入。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxko69QV4MSAicCJEibJgjwqtkOV6mUBemj2SsciacibyUWTjPDY6bzyzmswUQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

一般而言，对于大部分场景来说异步回调的形式就可以了，只有那种需要完全保证不能丢失消息的场景我们做一套完整的解决方案。

**MQ丢失**

如果生产者保证消息发送到MQ，而MQ收到消息后还在内存中，这时候宕机了又没来得及同步给从节点，就有可能导致消息丢失。

比如RocketMQ：

RocketMQ分为同步刷盘和异步刷盘两种方式，默认的是异步刷盘，就有可能导致消息还未刷到硬盘上就丢失了，可以通过设置为同步刷盘的方式来保证消息可靠性，这样即使MQ挂了，恢复的时候也可以从磁盘中去恢复消息。

比如Kafka也可以通过配置做到：

```yml
acks=all 只有参与复制的所有节点全部收到消息，才返回生产者成功。这样的话除非所有的节点都挂了，消息才会丢失。
replication.factor=N,设置大于1的数，这会要求每个partion至少有2个副本
min.insync.replicas=N，设置大于1的数，这会要求leader至少感知到一个follower还保持着连接
retries=N，设置一个非常大的值，让生产者发送失败一直重试
```

虽然我们可以通过配置的方式来达到MQ本身高可用的目的，但是都对性能有损耗，怎样配置需要根据业务做出权衡。

**消费者丢失**

消费者丢失消息的场景：消费者刚收到消息，此时服务器宕机，MQ认为消费者已经消费，不会重复发送消息，消息丢失。

RocketMQ默认是需要消费者回复ack确认，而kafka需要手动开启配置关闭自动offset。

消费方不返回ack确认，重发的机制根据MQ类型的不同发送时间间隔、次数都不尽相同，如果重试超过次数之后会进入死信队列，需要手工来处理了。（Kafka没有这些）

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxkoRvWVbZ3Udm14aHzicIoNIShjYmib8n1WYSwJpHKHM56UH1Zd1eD6BkCg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

#### 6.4. 如果一直消费失败导致消息积压怎么处理？

因为考虑到时消费者消费一直出错的问题，那么我们可以从以下几个角度来考虑：

1. 消费者出错，肯定是程序或者其他问题导致的，如果容易修复，先把问题修复，让consumer恢复正常消费
2. 如果时间来不及处理很麻烦，做转发处理，写一个临时的consumer消费方案，先把消息消费，然后再转发到一个新的topic和MQ资源，这个新的topic的机器资源单独申请，要能承载住当前积压的消息
3. 处理完积压数据后，修复consumer，去消费新的MQ和现有的MQ数据，新MQ消费完成后恢复原状

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxkoj8gCMjuuf8QpueCY8VyF6Y9bmpawQGOpDicfZWLvT2yOYsFCDA8lQrQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom: 67%;" />

#### 6.5. 那如果消息积压达到磁盘上限，消息被删除了怎么办？

最初，我们发送的消息记录是落库保存了的，而转发发送的数据也保存了，那么我们就可以通过这部分数据来找到丢失的那部分数据，再单独跑个脚本重发就可以了。如果转发的程序没有落库，那就和消费方的记录去做对比，只是过程会更艰难一点。

#### 6.6. 说了这么多，那你说说RocketMQ实现原理吧？

RocketMQ由NameServer注册中心集群、Producer生产者集群、Consumer消费者集群和若干Broker（RocketMQ进程）组成，它的架构原理是这样的：

1. Broker在启动的时候去向所有的NameServer注册，并保持长连接，每30s发送一次心跳
2. Producer在发送消息的时候从NameServer获取Broker服务器地址，根据负载均衡算法选择一台服务器来发送消息
3. Conusmer消费消息的时候同样从NameServer获取Broker地址，然后主动拉取消息来消费

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxkoHe5dBgwR6icK4YFhibp8YfFP4UMRL9qB7gDKLp6f43fq49WAiaAFj6PHQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 6.7. 为什么RocketMQ不使用Zookeeper作为注册中心呢？

我认为有以下几个点是不使用zookeeper的原因：

1. 根据CAP理论，同时最多只能满足两个点，而zookeeper满足的是CP，也就是说zookeeper并不能保证服务的可用性，zookeeper在进行选举的时候，整个选举的时间太长，期间整个集群都处于不可用的状态，而这对于一个注册中心来说肯定是不能接受的，作为服务发现来说就应该是为可用性而设计。
2. 基于性能的考虑，NameServer本身的实现非常轻量，而且可以通过增加机器的方式水平扩展，增加集群的抗压能力，而zookeeper的写是不可扩展的，而zookeeper要解决这个问题只能通过划分领域，划分多个zookeeper集群来解决，首先操作起来太复杂，其次这样还是又违反了CAP中的A的设计，导致服务之间是不连通的。
3. 持久化的机制来带的问题，ZooKeeper 的 ZAB 协议对每一个写请求，会在每个 ZooKeeper 节点上保持写一个事务日志，同时再加上定期的将内存数据镜像（Snapshot）到磁盘来保证数据的一致性和持久性，而对于一个简单的服务发现的场景来说，这其实没有太大的必要，这个实现方案太重了。而且本身存储的数据应该是高度定制化的。
4. 消息发送应该弱依赖注册中心，而RocketMQ的设计理念也正是基于此，生产者在第一次发送消息的时候从NameServer获取到Broker地址后缓存到本地，如果NameServer整个集群不可用，短时间内对于生产者和消费者并不会产生太大影响。

#### 6.8. 那Broker是怎么保存数据的呢？

RocketMQ主要的存储文件包括commitlog文件、consumequeue文件、indexfile文件。

Broker在收到消息之后，会把消息保存到commitlog的文件当中，而同时在分布式的存储当中，每个broker都会保存一部分topic的数据，同时，每个topic对应的messagequeue下都会生成consumequeue文件用于保存commitlog的物理位置偏移量offset，indexfile中会保存key和offset的对应关系。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxko81b6Wc0tpuRmDgsEiak69pwrh1gYZKVx2QzvXuZVM6zx0Nfn6oHzYibg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

CommitLog文件保存于${Rocket_Home}/store/commitlog目录中，从图中我们可以明显看出来文件名的偏移量，每个文件默认1G，写满后自动生成一个新的文件。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxkoeGiaVZ4SaicZW1VL7wvGxqbYumiasOqoDWmIWRuZaREYHZ1IDoQfib1Ujg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

由于同一个topic的消息并不是连续的存储在commitlog中，消费者如果直接从commitlog获取消息效率非常低，所以通过consumequeue保存commitlog中消息的偏移量的物理地址，这样消费者在消费的时候先从consumequeue中根据偏移量定位到具体的commitlog物理文件，然后根据一定的规则（offset和文件大小取模）在commitlog中快速定位。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxko2f8ff4mVSR1P1pmJ9DesqRCqZxqaSfxv3Nk12XsBCUKzhEUMxjDCJg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 6.9. Master和Slave之间是怎么同步数据的呢？

而消息在master和slave之间的同步是根据raft协议来进行的：

1. 在broker收到消息后，会被标记为uncommitted状态
2. 然后会把消息发送给所有的slave
3. slave在收到消息之后返回ack响应给master
4. master在收到超过半数的ack之后，把消息标记为committed
5. 发送committed消息给所有slave，slave也修改状态为committed

#### 6.10. 你知道RocketMQ为什么速度快吗？

是因为使用了顺序存储、Page Cache和异步刷盘。

1. 我们在写入commitlog的时候是顺序写入的，这样比随机写入的性能就会提高很多
2. 写入commitlog的时候并不是直接写入磁盘，而是先写入操作系统的PageCache
3. 最后由操作系统异步将缓存中的数据刷到磁盘

#### 6.11. 什么是事务、半事务消息？怎么实现的？

事务消息就是MQ提供的类似XA的分布式事务能力，通过事务消息可以达到分布式事务的最终一致性。

半事务消息就是MQ收到了生产者的消息，但是没有收到二次确认，不能投递的消息。

实现原理如下：

1. 生产者先发送一条半事务消息到MQ
2. MQ收到消息后返回ack确认
3. 生产者开始执行本地事务
4. 如果事务执行成功发送commit到MQ，失败发送rollback
5. 如果MQ长时间未收到生产者的二次确认commit或者rollback，MQ对生产者发起消息回查
6. 生产者查询事务执行最终状态
7. 根据查询事务状态再次提交二次确认

最终，如果MQ收到二次确认commit，就可以把消息投递给消费者，反之如果是rollback，消息会保存下来并且在3天后被删除。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUnL2LK2cEGiaQHADicP6dUxkon2hN1OQVqusmEQuVlO84SFBjkCj0BjBo4ZSLXegOBGV6lEicsGhD7ug/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 6.12. RabbitMQ相关问题

###### 6.12.1. RabbitMQ的工作模式

1. **simple模式（即最简单的收发模式）**

![在这里插入图片描述](https://user-gold-cdn.xitu.io/2020/4/13/1717348d49b7ccb7?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

- 消息产生消息，将消息放入队列
- 消息的消费者(consumer) 监听 消息队列,如果队列中有消息,就消费掉,消息被拿走后,自动从队列中删除(隐患 消息可能没有被消费者正确处理,已经从队列中消失了,造成消息的丢失，这里可以设置成手动的ack,但如果设置成手动ack，处理完后要及时发送ack消息给队列，否则会造成内存溢出)。

2. **work工作模式(资源的竞争)**

![在这里插入图片描述](https://user-gold-cdn.xitu.io/2020/4/13/1717348d4a6f6be6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

- 消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2同时监听同一个队列,消息被消费。C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患：高并发情况下,默认会产生某一个消息被多个消费者共同使用,可以设置一个开关(syncronize) 保证一条消息只能被一个消费者使用)。

3. **publish/subscribe发布订阅(共享资源)**

![在这里插入图片描述](https://user-gold-cdn.xitu.io/2020/4/13/1717348d4a57e741?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

- 每个消费者监听自己的队列；
- 生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息。

4. **routing路由模式**

![在这里插入图片描述](https://user-gold-cdn.xitu.io/2020/4/13/1717348d7605829e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

- 消息生产者将消息发送给交换机按照路由判断,路由是字符串(info) 当前产生的消息携带路由字符(对象的方法),交换机根据路由的key,只能匹配上路由key对应的消息队列,对应的消费者才能消费消息;
- 根据业务功能定义路由字符串
- 从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中。
- 业务场景:error 通知;EXCEPTION;错误通知的功能;传统意义的错误通知;客户通知;利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可以自定义消费者,实时接收错误;

5. **topic 主题模式(路由模式的一种)**

![在这里插入图片描述](https://user-gold-cdn.xitu.io/2020/4/13/1717348d779d8b8d?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

- 星号井号代表通配符
- 星号代表多个单词,井号代表一个单词
- 路由功能添加模糊匹配
- 消息产生者产生消息,把消息交给交换机
- 交换机根据key的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消费

###### 6.12.2. 如何保证RabbitMQ消息的顺序性

- 拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点；

- 或者就一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

###### 6.12.3. 消息怎么路由？

消息提供方->路由->一至多个队列消息发布到交换器时，消息将拥有一个路由键（routing key），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；

常用的交换器主要分为一下三种：

1. fanout：如果交换器收到消息，将会广播到所有绑定的队列上
2. direct：如果路由键完全匹配，消息就被投递到相应的队列
3. topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符

###### 6.12.4. 如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？

先说为什么会重复消费：正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；

但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。

针对以上问题，一个解决思路是：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；

- 比如：在写入消息队列的数据做唯一标示，消费消息时，根据唯一标识判断是否消费过；
- 假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。

###### 6.12.5. 如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？

**发送方确认模式**

- 将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。
- 一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。
- 如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。
- 发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。

**接收方确认机制**

- 消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。
- 这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；

**几种特殊情况**

- 如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）
- 如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。

###### 6.12.6.如何保证RabbitMQ消息的可靠传输？

- 消息不可靠的情况可能是消息丢失，劫持等原因；
- 丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；

1. **生产者丢失消息**：从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；

   transaction机制就是说：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；

   confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；

   rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；

   如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。

2. **消息队列丢数据**：消息持久化。

   处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。

   这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。

   这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。

   那么如何持久化呢？

   这里顺便说一下吧，其实也很容易，就下面两步

   ​	1. 将queue的持久化标识durable设置为true,则代表是一个持久的队列

   ​	2. 发送消息的时候将deliveryMode=2

   这样设置以后，即使rabbitMQ挂了，重启后也能恢复数据

3. **消费者丢失消息**：消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！

   消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；

   如果这时处理消息失败，就会丢失该消息；

   解决方案：处理消息成功后，手动回复确认消息。

###### 6.12.7. 如何保证高可用的？RabbitMQ 的集群

- RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

1. **单机模式**，就是 Demo 级别的，一般就是你本地启动了玩玩儿的?，没人生产用单机模式
2. **普通集群模式**：
   - 意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。
   - 你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。
3. **镜像集群模式**：
   - 这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。
   - 这样的好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。

###### 6.12.8. 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，怎么办？

- 消息积压处理办法：临时紧急扩容：

- 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 cnosumer 都停掉。新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。
  MQ中消息失效：假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。

- mq消息队列块满了：如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。

----

## 7. 分布式相关

#### 7.1. 分布式锁

**实现**

- 加锁命令：SETNX key value，当键不存在时，对键进行设置操作并返回成功，否则返回失败。KEY 是锁的唯一标识，一般按业务来决定命名。
- 解锁命令：DEL key，通过删除键值对释放锁，以便其他线程可以通过 SETNX 命令来获取锁。
- 锁超时：EXPIRE key timeout, 设置 key 的超时时间，以保证即使锁没有被显式释放，锁也可以在一定时间后自动释放，避免资源被永远锁住。

**存在的问题及及解决方案**

1. **setnx 和 expire 非原子性**：如果 setnx 成功，在设置锁超时时间后，服务器挂掉、重启或网络问题等，导致 expire 命令没有执行，锁没有设置超时时间变成死锁。**可以使用 set key value ex timeout nx命令，该命令是原子操作，或者使用 lua 脚本来解决此问题**
2. **锁误解除**：如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。**通过在 value 中设置当前线程加锁的标识，在删除之前验证 key 对应的 value 判断锁是否是当前线程持有。**
3. **超时解锁导致并发**：如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。
   1. 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。
   2. 为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间
4. **不可重入**：当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。

```java
// 如果 lock_key 不存在
if (redis.call('exists', KEYS[1]) == 0)
then
    // 设置 lock_key 线程标识 1 进行加锁
    redis.call('hset', KEYS[1], ARGV[2], 1);
    // 设置过期时间
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
    end;
// 如果 lock_key 存在且线程标识是当前欲加锁的线程标识
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1)
    // 自增
    then redis.call('hincrby', KEYS[1], ARGV[2], 1);
    // 重置过期时间
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
    end;
// 如果加锁失败，返回锁剩余时间
return redis.call('pttl', KEYS[1]);
```

5. **无法等待锁释放**：使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息
6. **集群带来的问题**：
   1. 在包含主从模式的集群部署方式中，当主节点挂掉时，从节点会取而代之，但客户端无明显感知。当客户端 A 成功加锁，指令还未同步，此时主节点挂掉，从节点提升为主节点，新的主节点没有锁的数据，当客户端 B 加锁时就会成功。
   2. 因为网络问题，导致 Redis master 节点跟 slave 节点和 sentinel 集群处于不同的网络分区，因为 sentinel 集群无法感知到 master 的存在，所以将 slave 节点提升为 master 节点，此时存在两个不同的 master 节点。当不同的客户端连接不同的 master 节点时，两个客户端可以同时拥有同一把锁。

**Redis 以其高性能著称，但使用其实现分布式锁来解决并发仍存在一些困难。Redis 分布式锁只能作为一种缓解并发的手段，如果要完全解决并发问题，仍需要数据库的防并发手段。**

#### 7.2. 分布式 id 生成策略

**特性**

- 唯一性：确保生成的ID是全网唯一的。
- 有序递增性：确保生成的ID是对于某个用户或者业务是按一定的数字有序递增的。
- 高可用性：确保任何时候都能正确的生成ID。
- 带时间：ID里面包含时间，一眼扫过去就知道哪天的交易。

**生成方案**

1. UUID：算法的核心思想是结合机器的网卡、当地时间、一个随记数来生成UUID。
   - 优点：本地生成，生成简单，性能好，没有高可用风险
   - 缺点：长度过长，存储冗余，且无序不可读，查询效率低
2. 数据库自增ID：使用数据库的id自增策略，如 MySQL 的 auto_increment。并且可以使用两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。
   - 优点：数据库生成的ID绝对有序，高可用实现方式简单
   - 缺点：需要独立部署数据库实例，成本高，有性能瓶颈
3. 基于数据库的号段模式：为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下：

```mysql
CREATE TABLE id_generator (
  id int(10) NOT NULL,
  max_id bigint(20) NOT NULL COMMENT '当前最大id',
  step int(20) NOT NULL COMMENT '号段的布长',
  biz_type	int(20) NOT NULL COMMENT '业务类型',
  version int(20) NOT NULL COMMENT '版本号',
  PRIMARY KEY (`id`)
) 
```

biz_type ：代表不同业务类型

max_id ：当前最大的可用id

step ：代表号段的长度

version ：是一个乐观锁，每次都更新version，保证并发时数据的正确性

等这批号段ID用完，再次向数据库申请新号段，对`max_id`字段做一次`update`操作，`update max_id= max_id + step`，update成功则说明新号段获取成功，新的号段范围是`(max_id ,max_id +step]`。

```java
update id_generator set max_id = #{max_id+step}, version = version + 1 where version = # {version} and biz_type = XXX
```

由于多业务端可能同时操作，所以采用版本号`version`乐观锁方式更新，这种`分布式ID`生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。

4. 基于Redis模式：`Redis`也同样可以实现，原理就是利用`redis`的 `incr`命令实现ID的原子性自增。

```shell
127.0.0.1:6379> set seq_id 1     ## 初始化自增ID为1
OK
127.0.0.1:6379> incr seq_id      ## 增加1，并返回递增后的数值
(integer) 2
```

用`redis`实现需要注意一点，要考虑到redis持久化的问题。`redis`有两种持久化方式`RDB`和`AOF`

- `RDB`会定时打一个快照进行持久化，假如连续自增但`redis`没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。
- `AOF`会对每条写命令进行持久化，即使`Redis`挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致`Redis`重启恢复的数据时间过长。

5. 雪花算法

![img](http://pony-maggie.github.io/assets/images/2019/tech/12/snowflake-1.jpg)

算法产生的是一个long型 64 比特位的值，第一位未使用。接下来是41位的毫秒单位的时间戳，我们可以计算下：

```java
2^41/1000*60*60*24*365 = 69
```

也就是这个时间戳可以使用69年不重复，这个对于大部分系统够用了。

很多人这里会搞错概念，以为这个时间戳是相对于一个我们业务中指定的时间（一般是系统上线时间），而不是1970年。这里一定要注意。

10位的数据机器位，所以可以部署在1024个节点。

12位的序列，在毫秒的时间戳内计数。 支持每个节点每毫秒产生4096个ID序号，所以最大可以支持单节点差不多四百万的并发量，这个妥妥的够用了。

```java
public class SnowflakeIdWorker {
    /** 开始时间截 (这个用自己业务系统上线的时间) */
    private final long twepoch = 1575365018000L;

    /** 机器id所占的位数 */
    private final long workerIdBits = 10L;

    /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */
    private final long maxWorkerId = -1L ^ (-1L << workerIdBits);
    
    /** 序列在id中占的位数 */
    private final long sequenceBits = 12L;

    /** 机器ID向左移12位 */
    private final long workerIdShift = sequenceBits;

    /** 时间截向左移22位(10+12) */
    private final long timestampLeftShift = sequenceBits + workerIdBits;

    /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */
    private final long sequenceMask = -1L ^ (-1L << sequenceBits);

    /** 工作机器ID(0~1024) */
    private long workerId;

    /** 毫秒内序列(0~4095) */
    private long sequence = 0L;

    /** 上次生成ID的时间截 */
    private long lastTimestamp = -1L;

    //==============================Constructors=====================================
    /**
     * 构造函数
     * @param workerId 工作ID (0~1024)
     */
    public SnowflakeIdWorker(long workerId) {
        if (workerId > maxWorkerId || workerId < 0) {
            throw new IllegalArgumentException(String.format("workerId can't be greater than %d or less than 0", maxWorkerId));
        }
        this.workerId = workerId;
    }

    // ==============================Methods==========================================
    /**
     * 获得下一个ID (该方法是线程安全的)
     * @return SnowflakeId
     */
    public synchronized long nextId() {
        long timestamp = timeGen();

        //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常
        if (timestamp < lastTimestamp) {
            throw new RuntimeException(
                    String.format("Clock moved backwards.  Refusing to generate id for %d milliseconds", lastTimestamp - timestamp));
        }

        //如果是同一时间生成的，则进行毫秒内序列
        if (lastTimestamp == timestamp) {
            sequence = (sequence + 1) & sequenceMask;
            //毫秒内序列溢出
            if (sequence == 0) {
                //阻塞到下一个毫秒,获得新的时间戳
                timestamp = tilNextMillis(lastTimestamp);
            }
        }
        //时间戳改变，毫秒内序列重置
        else {
            sequence = 0L;
        }

        //上次生成ID的时间截
        lastTimestamp = timestamp;

        //移位并通过或运算拼到一起组成64位的ID
        return ((timestamp - twepoch) << timestampLeftShift) //
                | (workerId << workerIdShift) //
                | sequence;
    }

    /**
     * 阻塞到下一个毫秒，直到获得新的时间戳
     * @param lastTimestamp 上次生成ID的时间截
     * @return 当前时间戳
     */
    protected long tilNextMillis(long lastTimestamp) {
        long timestamp = timeGen();
        while (timestamp <= lastTimestamp) {
            timestamp = timeGen();
        }
        return timestamp;
    }

    /**
     * 返回以毫秒为单位的当前时间
     * @return 当前时间(毫秒)
     */
    protected long timeGen() {
        return System.currentTimeMillis();
    }
}
```

**由于该算法强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态**

5. 美团 Leaf 方案，支持分段号段模式和雪花算法模式，并且解决了雪花算法的时钟回拨问题

#### 7.3. 分布式事务

分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。例如在大型电商系统中，下单接口通常会扣减库存、减去优惠、生成订单 id, 而订单服务与库存、优惠、订单 id 都是不同的服务，下单接口的成功与否，不仅取决于本地的 db 操作，而且依赖第三方系统的结果，这时候分布式事务就保证这些操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。

**强一致性、弱一致性、最终一致性**

- **强一致性**：任何一次读都能读到某个数据的最近一次写的数据。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。简言之，在任意时刻，所有节点中的数据是一样的。

- **弱一致性**：数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。

- **最终一致性**：不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。

**CAP 原则**

CAP 原则又称 CAP 定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。

- 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）

- 可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）

- 分区容错性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。

CAP 原则的精髓就是要么 AP，要么 CP，要么 AC，但是不存在 CAP。如果在某个分布式系统中数据无副本， 那么系统必然满足强一致性条件， 因为只有独一数据，不会出现数据不一致的情况，此时 C 和 P 两要素具备，但是如果系统发生了网络分区状况或者宕机，必然导致某些数据不可以访问，此时可用性条件就不能被满足，即在此情况下获得了 CP 系统，但是 CAP 不可同时满足。

**BASE 理论**

BASE 理论指的是基本可用 Basically Available，软状态 Soft State，最终一致性 Eventual Consistency，核心思想是即便无法做到强一致性，但应该采用适合的方式保证最终一致性。

BASE，Basically Available Soft State Eventual Consistency 的简写，BASE 理论本质上是对 CAP 理论的延伸，是对 CAP 中 AP 方案的一个补充：

- BA：Basically Available 基本可用，分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。
- S：Soft State 软状态，允许系统存在中间状态，而该中间状态不会影响系统整体可用性。
- E：Consistency 最终一致性，系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。

**柔性事务**

不同于 ACID 的刚性事务，在分布式场景下基于 BASE 理论，就出现了柔性事务的概念。要想通过柔性事务来达到最终的一致性，就需要依赖于一些特性，这些特性在具体的方案中不一定都要满足，因为不同的方案要求不一样；但是都不满足的话，是不可能做柔性事务的。

**幂等操作**

在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，支付流程中第三方支付系统告知系统中某个订单支付成功，接收该支付回调接口在网络正常的情况下无论操作多少次都应该返回成功。

**使用场景**

- 转账：转账是最经典那的分布式事务场景，假设用户 A 使用银行 app 发起一笔跨行转账给用户 B，银行系统首先扣掉用户 A 的钱，然后增加用户 B 账户中的余额。此时就会出现 2 种异常情况：1. 用户 A 的账户扣款成功，用户 B 账户余额增加失败 2. 用户 A 账户扣款失败，用户 B 账户余额增加成功。对于银行系统来说，以上 2 种情况都是不允许发生，此时就需要分布式事务来保证转账操作的成功。
- 下单扣库存：在电商系统中，下单是用户最常见操作。在下单接口中必定会涉及生成订单 id, 扣减库存等操作，对于微服务架构系统，订单 id 与库存服务一般都是独立的服务，此时就需要分布式事务来保证整个下单接口的成功。
- 同步超时：继续以电商系统为例，在微服务体系架构下，我们的支付与订单都是作为单独的系统存在。订单的支付状态依赖支付系统的通知，假设一个场景：我们的支付系统收到来自第三方支付的通知，告知某个订单支付成功，接收通知接口需要同步调用订单服务变更订单状态接口，更新订单状态为成功。流程图如下，从图中可以看出有两次调用，第三方支付调用支付服务，以及支付服务调用订单服务，这两步调用都可能出现调用超时的情况，此处如果没有分布式事务的保证，就会出现用户订单实际支付情况与最终用户看到的订单支付情况不一致的情况。

![img](https://xiaomi-info.github.io/2020/01/02/distributed-transaction/notify-message.png)

**解决方案**

**两段式提交 / XA**

两阶段提交，顾名思义就是要分两步提交。存在一个负责协调各个本地资源管理器的事务管理器，本地资源管理器一般是由数据库实现，事务管理器在第一阶段的时候询问各个资源管理器是否都就绪？如果收到每个资源的回复都是 yes，则在第二阶段提交事务，如果其中任意一个资源的回复是 no, 则回滚事务。

![img](https://xiaomi-info.github.io/2020/01/02/distributed-transaction/XA-second.jpg)

大致的流程：

第一阶段（prepare）：事务管理器向所有本地资源管理器发起请求，询问是否是 ready 状态，所有参与者都将本事务能否成功的信息反馈发给协调者；
第二阶段 (commit/rollback)：事务管理器根据所有本地资源管理器的反馈，通知所有本地资源管理器，步调一致地在所有分支上提交或者回滚。

存在的问题：

- 同步阻塞：当参与事务者存在占用公共资源的情况，其中一个占用了资源，其他事务参与者就只能阻塞等待资源释放，处于阻塞状态。
- 单点故障：一旦事务管理器出现故障，整个系统不可用
- 数据不一致：在阶段二，如果事务管理器只发送了部分 commit 消息，此时网络发生异常，那么只有部分参与者接收到 commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。
- 不确定性：当协事务管理器发送 commit 之后，并且此时只有一个参与者收到了 commit，那么当该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确定该条消息是否提交成功。

**TCC**

关于 TCC（Try-Confirm-Cancel）的概念，最早是由 Pat Helland 于 2007 年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。 TCC 事务机制相比于上面介绍的 XA，解决了其几个缺点：

1. 解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。
2. 同步阻塞：引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。
3. 数据一致性，有了补偿机制之后，由业务活动管理器控制一致性

TCC(Try Confirm Cancel)
Try 阶段：尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）
Confirm 阶段：确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性。要求具备幂等设计，Confirm 失败后需要进行重试。
Cancel 阶段：取消执行，释放 Try 阶段预留的业务资源 Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。

在 Try 阶段，是对业务系统进行检查及资源预览，比如订单和存储操作，需要检查库存剩余数量是否够用，并进行预留，预留操作的话就是新建一个可用库存数量字段，Try 阶段操作是对这个可用库存数量进行操作。
基于 TCC 实现分布式事务，会将原来只需要一个接口就可以实现的逻辑拆分为 Try、Confirm、Cancel 三个接口，所以代码实现复杂度相对较高。

**本地消息表**

本地消息表这个方案最初是 ebay 架构师 Dan Pritchett 在 2008 年发表给 ACM 的文章。该方案中会有消息生产者与消费者两个角色，假设系统 A 是消息生产者，系统 B 是消息消费者，其大致流程如下：
![img](https://xiaomi-info.github.io/2020/01/02/distributed-transaction/native-message.jpg)

1. 当系统 A 被其他系统调用发生数据库表更操作，首先会更新数据库的业务表，其次会往相同数据库的消息表中插入一条数据，两个操作发生在同一个事务中
2. 系统 A 的脚本定期轮询本地消息往 mq 中写入一条消息，如果消息发送失败会进行重试
3. 系统 B 消费 mq 中的消息，并处理业务逻辑。如果本地事务处理失败，会在继续消费 mq 中的消息进行重试，如果业务上的失败，可以通知系统 A 进行回滚操作

本地消息表实现的条件：

1. 消费者与生成者的接口都要支持幂等
2. 生产者需要额外的创建消息表
3. 需要提供补偿逻辑，如果消费者业务失败，需要生产者支持回滚操作

容错机制：

1. 步骤 1 失败时，事务直接回滚
2. 步骤 2、3 写 mq 与消费 mq 失败会进行重试
3. 步骤 3 业务失败系统 B 向系统 A 发起事务回滚操作

此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。

**可靠消息最终一致性**

大致流程如下：
![img](https://xiaomi-info.github.io/2020/01/02/distributed-transaction/mq-message.jpg)

1. A 系统先向 mq 发送一条 prepare 消息，如果 prepare 消息发送失败，则直接取消操作
2. 如果消息发送成功，则执行本地事务
3. 如果本地事务执行成功，则想 mq 发送一条 confirm 消息，如果发送失败，则发送回滚消息
4. B 系统定期消费 mq 中的 confirm 消息，执行本地事务，并发送 ack 消息。如果 B 系统中的本地事务失败，会一直不断重试，如果是业务失败，会向 A 系统发起回滚请求

5.mq 会定期轮询所有 prepared 消息调用系统 A 提供的接口查询消息的处理情况，如果该 prepare 消息本地事务处理成功，则重新发送 confirm 消息，否则直接回滚该消息

该方案与本地消息最大的不同是去掉了本地消息表，其次本地消息表依赖消息表重试写入 mq 这一步由本方案中的轮询 prepare 消息状态来重试或者回滚该消息替代。其实现条件与余容错方案基本一致。目前市面上实现该方案的只有阿里的 RocketMq。

**尽最大努力通知**

最大努力通知是最简单的一种柔性事务，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果 不影响主动方的处理结果。

这个方案的大致意思就是：

1. 系统 A 本地事务执行完之后，发送个消息到 MQ；
2. 这里会有个专门消费 MQ 的服务，这个服务会消费 MQ 并调用系统 B 的接口；
3. 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B, 反复 N 次，最后还是不行就放弃。

**seata原理**

Seata的分布式事务解决方案是业务层面的解决方案，只依赖于单台数据库的事务能力。Seata框架中一个分布式事务包含3中角色：

- Transaction Coordinator (TC)： 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。
- Transaction Manager (TM)： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。
- Resource Manager (RM)： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。

其中，TM是一个分布式事务的发起者和终结者，TC负责维护分布式事务的运行状态，而RM则负责本地事务的运行。如下图所示：

![img](https:////upload-images.jianshu.io/upload_images/448235-a1c292d157a0499d.PNG?imageMogr2/auto-orient/strip|imageView2/2/w/770/format/webp)

下面是一个分布式事务在Seata中的执行流程：

1. TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID。
2. XID 在微服务调用链路的上下文中传播。
3. RM 向 TC 注册分支事务，接着执行这个分支事务并提交（重点：RM在第一阶段就已经执行了本地事务的提交/回滚），最后将执行结果汇报给TC。
4. TM 根据 TC 中所有的分支事务的执行情况，发起全局提交或回滚决议。
5. TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。

#### 7.4. 一致性哈希

当数据太大而无法存储在一个节点或机器上时，问题变得更加有趣，系统中需要多个这样的节点或机器来存储它。比如，使用多个 Web 缓存中间件的系统。**那如何确定哪个 key 存储在哪个节点上？针对该问题，最简单的解决方案是使用哈希取模来确定。** 给定一个 key，先对 key 进行哈希运算，将其除以系统中的节点数，然后将该 key 放入该节点。同样，在获取 key 时，对 key 进行哈希运算，再除以节点数，然后转到该节点并获取值。如果服务器数量发生变化，取模运算的结果会受到较大影响，还会涉及到大量数据迁移。一致性哈希算法是在哈希算法基础上提出，具有更好的扩展性。

**实现原理**

一致性哈希算法通过一个叫作一致性哈希环的数据结构实现。这个环的起点是 0，终点是 2^32 - 1，并且起点与终点连接，故这个环的整数分布范围是 [0, 2^32-1]，如下图所示：

![hash-ring.jpg](https://segmentfault.com/img/bVbA7aA)

**将对象放置到哈希环**

假设我们有 "semlinker"、"kakuqo"、"lolo"、"fer" 四个对象，分别简写为 o1、o2、o3 和 o4，然后使用哈希函数计算这个对象的 hash 值，值的范围是 [0, 2^32-1]：

![hash-ring-hash-objects.jpg](https://segmentfault.com/img/bVbA7aB)

图中对象的映射关系如下：

```shell
hash(o1) = k1; hash(o2) = k2;
hash(o3) = k3; hash(o4) = k4;
```

**将服务器放置到哈希环**

接着使用同样的哈希函数，我们将服务器也放置到哈希环上，可以选择服务器的 IP 或主机名作为键进行哈希，这样每台服务器就能确定其在哈希环上的位置。这里假设我们有 3 台缓存服务器，分别为 cs1、cs2 和 cs3：

![hash-ring-hash-servers.jpg](https://segmentfault.com/img/bVbA7aG)

图中服务器的映射关系如下：

```shell
hash(cs1) = t1; hash(cs2) = t2; hash(cs3) = t3; # Cache Server
```

**为对象选择服务器**

**将对象和服务器都放置到同一个哈希环后，在哈希环上顺时针查找距离这个对象的 hash 值最近的机器，即是这个对象所属的机器。** 以 o2 对象为例，顺序针找到最近的机器是 cs2，故服务器 cs2 会缓存 o2 对象。而服务器 cs1 则缓存 o1，o3 对象，服务器 cs3 则缓存 o4 对象。

![hash-ring-objects-servers.jpg](https://segmentfault.com/img/bVbA7aH)

**服务器增加的情况**

假设由于业务需要，我们需要增加一台服务器 cs4，经过同样的 hash 运算，该服务器最终落于 t1 和 t2 服务器之间，具体如下图所示：

![hash-ring-add-server.jpg](https://segmentfault.com/img/bVbA7aI)

对于上述的情况，只有 t1 和 t2 服务器之间的对象需要重新分配。在以上示例中只有 o3 对象需要重新分配，即它被重新到 cs4 服务器。在前面我们已经分析过，如果使用简单的取模方法，当新添加服务器时可能会导致大部分缓存失效，而使用一致性哈希算法后，这种情况得到了较大的改善，因为只有少部分对象需要重新分配。

**服务器减少的情况**

假设 cs3 服务器出现故障导致服务下线，这时原本存储于 cs3 服务器的对象 o4，需要被重新分配至 cs2 服务器，其它对象仍存储在原有的机器上。

![hash-ring-remove-server.jpg](https://segmentfault.com/img/bVbA7aJ)

**虚拟节点**

到这里一致性哈希的基本原理已经介绍完了，但对于新增服务器的情况还存在一些问题。新增的服务器 cs4 只分担了 cs1 服务器的负载，服务器 cs2 和 cs3 并没有因为 cs4 服务器的加入而减少负载压力。如果 cs4 服务器的性能与原有服务器的性能一致甚至可能更高，那么这种结果并不是我们所期望的。

**针对这个问题，我们可以通过引入虚拟节点来解决负载不均衡的问题。即将每台物理服务器虚拟为一组虚拟服务器，将虚拟服务器放置到哈希环上，如果要确定对象的服务器，需先确定对象的虚拟服务器，再由虚拟服务器确定物理服务器。**

![ch-virtual-nodes.jpg](https://segmentfault.com/img/bVbA7aK)

图中 o1 和 o2 表示对象，v1 ~ v6 表示虚拟服务器，s1 ~ s3 表示物理服务器。

**一致性哈希算法实现**

这里我们只介绍不带虚拟节点的一致性哈希算法实现：

```java
import java.util.SortedMap;
import java.util.TreeMap;

public class ConsistentHashingWithoutVirtualNode {
    //待添加入Hash环的服务器列表
    private static String[] servers = {"192.168.0.1:8888", "192.168.0.2:8888", 
      "192.168.0.3:8888"};

    //key表示服务器的hash值，value表示服务器
    private static SortedMap<Integer, String> sortedMap = new TreeMap<Integer, String>();

    //程序初始化，将所有的服务器放入sortedMap中
    static {
        for (int i = 0; i < servers.length; i++) {
            int hash = getHash(servers[i]);
            System.out.println("[" + servers[i] + "]加入集合中, 其Hash值为" + hash);
            sortedMap.put(hash, servers[i]);
        }
    }

    //得到应当路由到的结点
    private static String getServer(String key) {
        //得到该key的hash值
        int hash = getHash(key);
        //得到大于该Hash值的所有Map
        SortedMap<Integer, String> subMap = sortedMap.tailMap(hash);
        if (subMap.isEmpty()) {
            //如果没有比该key的hash值大的，则从第一个node开始
            Integer i = sortedMap.firstKey();
            //返回对应的服务器
            return sortedMap.get(i);
        } else {
            //第一个Key就是顺时针过去离node最近的那个结点
            Integer i = subMap.firstKey();
            //返回对应的服务器
            return subMap.get(i);
        }
    }

    //使用FNV1_32_HASH算法计算服务器的Hash值
    private static int getHash(String str) {
        final int p = 16777619;
        int hash = (int) 2166136261L;
        for (int i = 0; i < str.length(); i++)
            hash = (hash ^ str.charAt(i)) * p;
        hash += hash << 13;
        hash ^= hash >> 7;
        hash += hash << 3;
        hash ^= hash >> 17;
        hash += hash << 5;

        // 如果算出来的值为负数则取其绝对值
        if (hash < 0)
            hash = Math.abs(hash);
        return hash;
    }

    public static void main(String[] args) {
        String[] keys = {"semlinker", "kakuqo", "fer"};
        for (int i = 0; i < keys.length; i++)
            System.out.println("[" + keys[i] + "]的hash值为" + getHash(keys[i])
                    + ", 被路由到结点[" + getServer(keys[i]) + "]");
    }
}
```

以上代码成功运行后，在控制台会输出以下结果：

```java
[192.168.0.1:8888]加入集合中, 其Hash值为1326271016
[192.168.0.2:8888]加入集合中, 其Hash值为1132535844
[192.168.0.3:8888]加入集合中, 其Hash值为115798597

[semlinker]的hash值为1549041406, 被路由到结点[192.168.0.3:8888]
[kakuqo]的hash值为463104755, 被路由到结点[192.168.0.2:8888]
[fer]的hash值为1677150790, 被路由到结点[192.168.0.3:8888]
```

----

## 8. 计算机网络

#### 8.1. 简述网络模型

OSI 模型由七层模型构成，网络七层模型是一个标准，而非实现。TCP/IP 模型将 OSI 模型由七层简化为四层，传输层和网络层被完整保留，因此网络中最核心的技术就是传输层和网络层技术。网络四层模型是一个实现的应用模型。

- 网络访问层：ARP、RARP

- 互联网层：ICMP、IP

- 传输层：TCP、UDP

- 应用层：DNS、FTP、HTTP、SMTP、TELNET

<img src="https://user-gold-cdn.xitu.io/2017/8/25/3fe5c91aafa1173c22b944e0ed8746c8?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="file" style="zoom:67%;" />

#### 8.2. 简述三次握手和四次挥手的过程。

###### 8.2.1. 三次握手

最开始的时候客户端和服务器都是处于CLOSED状态。主动打开连接的为客户端，被动打开连接的是服务器。

1. TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了LISTEN（监听）状态；
2. TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。
3. TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。
4. TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。
5. 当服务器收到客户端的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了

<img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA1MTEwNDA1NjY2?x-oss-process=image/format,png" alt="三次握手" style="zoom:67%;" />

**为什么TCP客户端最后还要发送一次确认呢？**

主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。

如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。

如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。

###### 8.2.2. 四次挥手

数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于ESTABLISHED状态，然后客户端主动关闭，服务器被动关闭。

1. 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2. 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
3. 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4. 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
5. 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗ *∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
6. 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。

<img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy?x-oss-process=image/format,png" alt="四次挥手" style="zoom:67%;" />

**为什么客户端最后还要等待2MSL？**

MSL（Maximum Segment Lifetime），TCP允许不同的实现可以设置不同的MSL值。

第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。

第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。

**为什么建立连接是三次握手，关闭连接确是四次挥手呢？**

因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中**ACK报文是用来应答的，SYN报文是用来同步的**。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，"你发的FIN报文我收到了"。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

#### 8.3. HTTP 和 HTTPS 的区别

###### 8.3.1. http协议的缺点

- 通信使用明文，内容可能被窃听（重要密码泄露）
- 不验证通信方身份，有可能遭遇伪装（跨站点请求伪造）
- 无法证明报文的完整性，有可能已遭篡改（运营商劫持）

https是在http协议基础上加入加密处理和认证机制以及完整性保护，即http+加密+认证+完整性保护=https。https并非应用层的一种新协议，只是http通信接口部分用ssl/tls协议代替而已。通常http直接和tcp通信，当使用ssl时则演变成先和ssl通信，再由ssl和tcp通信。所谓https，其实就是身披ssl协议这层外壳的http。

###### 8.3.2. SSL/TSL

SSL协议位于TCP/IP协议与各种应用层协议之间，为数据通讯提供安全支持。SSL协议可分为两层：

- SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。
- SSL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。

###### 8.3.3. 对称加密和非对称加密

- 对称密钥加密，又称私钥加密，即信息的发送方和接收方用同一个密钥去加密和解密数据。它的最大优势是加/解密速度快，适合于对大数据量进行加密，但密钥管理困难。
- 非对称密钥加密，又称公钥加密，它需要使用一对密钥来分别完成加密和解密操作，一个公开发布，即公开密钥，另一个由用户自己秘密保存，即私用密钥。信息发送者用公开密钥去加密，而信息接收者则用私用密钥去解密。从功能角度而言非对称加密比对称加密功能强大，但加密和解密速度却比对称密钥加密慢得多。

###### 8.3.4. SSL/TSL协议基本原理

SSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密，但是这里有两个问题：

1. 如何保证公钥不被篡改？
   解决方法：将公钥放在数字证书中，只要证书是可信的，公钥就是可信的。
2. 公钥加密计算量太大，如何减少耗用的时间？
   解决方法：每一次对话（session），客户端和服务器端都生成一个"对话密钥"（session key），用它来加密信息。由于"对话密钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减少了加密运算的消耗时间。

因此，SSL/TLS协议的基本过程是这样的：

1. 客户端向服务器端索要并验证公钥。
2. 双方协商生成“对话密钥”。
3. 双方采用“对话密钥”进行加密通信。

###### 8.3.5. HTTPS工作原理

1. 客户端发起HTTPS请求
   用户在浏览器里输入一个https网址，然后连接到server的443端口。
2. 服务端的配置
   采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请，区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面。
3. 传送证书
   这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。
4. 客户端解析证书
   这部分工作是由客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。
   1. 首先浏览器读取证书中的证书所有者、有效期等信息进行一一校验
   2. 浏览器开始查找操作系统中已内置的受信任的证书发布机构CA，与服务器发来的证书中的颁发者CA比对，用于校验证书是否为合法机构颁发
   3. 如果找不到，浏览器就会报错，说明服务器发来的证书是不可信任的。
   4. 如果找到，那么浏览器就会从操作系统中取出颁发者CA 的公钥(多数浏览器开发商发布
      版本时，会事先在内部植入常用认证机关的公开密钥)，然后对服务器发来的证书里面的签名进行解密
   5. 浏览器使用相同的hash算法计算出服务器发来的证书的hash值，将这个计算的hash值与证书中签名做对比
   6. 对比结果一致，则证明服务器发来的证书合法，没有被冒充
   7. 此时浏览器就可以读取证书中的公钥，用于后续加密了
5. 传送加密信息
   这部分传送的是用证书加密后的随机值(私钥)，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。
6. 服务端解密信息
   服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密
7. 传输加密后的信息
   这部分信息是服务端用私钥加密后的信息，可以在客户端被还原。
8. 客户端解密信息
   客户端用之前生成的私钥解密服务端传过来的信息，于是获取了解密后的内容，整个过程第三方即使监听到了数据，也束手无策。

###### 8.3.6 HTTP和HTTPS区别如下

1. https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
2. http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
3. http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
4. http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全

#### 8.4. 从浏览器输入网址到显示页面发生了什么？

1. **DNS解析**：

   - 从客户端缓存中查找是否有域名对应的IP地址（依次查找浏览器缓存、操作系统缓存、路由器缓存）

   - 如果客户端缓存中没有，则会从互联网服务提供商的缓存中查找

   - 当以上缓存中均为查询到，则向根域名服务器进行查询，比如 www.baidu.com，根服务器会返回一个.com域名服务器地址，客户端继续向这个.com域名服务器进一步请求，最终客户端会拿到一个IP地址并缓存起来

2. 建立TCP连接：客户端通过三次握手与服务器建立连接

3. 发送HTTP请求：浏览器向服务器发送报文，包括请求头、请求体

4. 服务器处理请求：服务器解析用户的请求并进行处理

5. 返回响应结果：服务器将响应报文发送给客户端

6. 关闭TCP连接：通过四次挥手关闭TCP连接

7. 浏览器解析HTML，布局渲染，绘制各个节点，将页面呈现给用户

----

## 9. Linux

#### 9. 1.CPU负载和CPU利用率的区别是什么？

首先可以通过`uptime`，`w`或者`top`命令看到CPU的平均负载。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhvwRIlJd8pSfSb6AAxw1kUhFPJ8KibRia4KxkHWHwBQvTOkhtib39Kxfvg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhDY6yINBYhEycwlZWr8XxGqhiaS5mozVMVZ3yq42H2dAyZWgQXxkFUqg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**Load Average** ：负载的3个数字，比如上图的4.86，5.28，5.00，分别代表系统在过去的1分钟，5分钟，15分钟内的系统平均负载。他代表的是**当前系统正在运行的和处于等待运行的进程数之和**。也指的是处于**可运行状态**和**不可中断状态**的平均进程数。

如果单核CPU的话，负载达到1就代表CPU已经达到满负荷的状态了，超过1，后面的进行就需要排队等待处理了。

如果是是多核多CPU的话，假设现在服务器是2个CPU，每个CPU2个核，那么总负载不超过4都没什么问题。

怎么查看CPU有多少核呢？

通过命令`cat /proc/cpuinfo | grep "model name"`查看CPU的情况。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhSuPhGGBMah9FW9Z6bI1lzsHwDCJiaepVIicic3JsD6GXl28ZBcJXR22Ag/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

通过`cat /proc/cpuinfo | grep "cpu cores"`查看CPU的核数

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhOemAFZSIiaase0bGTt4Mt8AXT4hJec9m26eQbvxrM6W1lI0QgPAglwA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)	

**CPU 利用率**：和负载不同，CPU利用率指的是当前**正在运行**的进程实时占用CPU的百分比，他是对一段时间内CPU使用状况的统计。

我举个栗子🌰：

假设你们公司厕所有1个坑位，有一个人占了坑位，这时候负载就是1，如果还有一个人在排队，那么负载就是2。

如果在1个小时内，A上厕所花了10分钟，B上厕所花了20分钟，剩下30分钟厕所都没人使用，那么这一个小时内利用率就是50%。

#### 9.2. 那如果CPU负载很高，利用率却很低该如何排查？

CPU负载很高，利用率却很低，说明处于等待状态的任务很多，负载越高，代表可能很多僵死的进程。通常这种情况是IO密集型的任务，大量请求在请求相同的IO，导致任务队列堆积。

同样，可以先通过`top`命令观察(截图只是示意，不代表真实情况)，假设发现现在确实是高负载低使用率。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhZtqWKVS8iad2rYo1Yj3BZ1pksWpkgdpicYms24qDnBLXFzJeOPFRJiciag/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

然后，再通过命令`ps -axjf`查看是否存在状态为`D+`状态的进程，这个状态指的就是不可中断的睡眠状态的进程。处于这个状态的进程无法终止，也无法自行退出，只能通过恢复其依赖的资源或者重启系统来解决。(对不起，我截不到D+的状态)

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhIM5P9GSeFqQ3cIgDiaNNPMpbMU5wJXZBw4fiaaT7CGSpDK1ntx9OUXfg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 9.3. 如果负载很低，利用率却很高如何排查？

如果你的公司只有一个厕所，外面没人排队，却有一个人在里面上了大半个小时，这说明什么？

两种可能：他没带纸，或者一些奇怪的事情发生了？

这表示CPU的任务并不多，但是任务执行的时间很长，大概率就是你写的代码本身有问题，通常是计算密集型任务，生成了大量耗时短的计算任务。

怎么排查？直接`top`命令找到使用率最高的任务，定位到去看看就行了。如果代码没有问题，那么过段时间CPU使用率就会下降的。

#### 9.4. 那如果CPU使用率达到100%呢？怎么排查？

1. 通过`top`找到占用率高的进程。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhuRsibVXxW9SRfyqpQ3BibwBQPtgsCBfDAaeXdYcVeQTUjuYYIocdqMeA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

2. 通过`top -Hp pid`找到占用CPU高的线程ID。这里找到958的线程ID

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhRs9ZKX1UAuuABVHeqWiaMJsDOUjGIjUyHnJAbLEicWgD4iaWQYaibklbag/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

3. 再把线程ID转化为16进制，`printf "0x%x\n" 958`，得到线程ID`0x3be`

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhKOCk3psjNH4lOMxJwKmP5033B8icpshzkQvdzDottaVh28kcZ6zJlxw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

4. 通过命令`jstack 163 | grep '0x3be' -C5 --color` 或者 `jstack 163|vim +/0x3be -` 找到有问题的代码

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhgPK9rmZ5npLAtgmIia4TLjFdGVrSXAAZeMn3m5RE8tKMLn9WBnU9CZw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 9.5.说说常见的Linux命令

###### 9.5.1. 常用的文件、目录命令

- `ls`：用户查看目录下的文件，`ls -a`可以用来查看隐藏文件，`ls -l`可以用于查看文件的详细信息，包括权限、大小、所有者等信息。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhibXXocCSBqic77sdcSXB4oSdjk0K5V5zh5Nj1YnBlj988yNV26hasoLA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- `touch`：用于创建文件。如果文件不存在，则创建一个新的文件，如果文件已存在，则会修改文件的时间戳。

- `cat`：cat是英文`concatenate`的缩写，用于查看文件内容。使用`cat`查看文件的话，不管文件的内容有多少，都会一次性显示，所以他不适合查看太大的文件。

- `more`：more和cat有点区别，more用于分屏显示文件内容。可以用`空格键`向下翻页，`b`键向上翻页

- `less`：和more类似，less用于分行显示

- `tail`：可能是平时用的最多的命令了，查看日志文件基本靠他了。一般用户`tail -fn 100 xx.log`查看最后的100行内容

###### 9.5.2. 常用的权限命令

- `chmod`：修改权限命令。一般用`+`号添加权限，`-`号删除权限，`x`代表执行权限，`r`代表读取权限，`w`代表写入权限，常见写法比如`chmod +x 文件名` 添加执行权限。

  还有另外一种写法，使用数字来授权，因为`r`=4，`w`=2，`x`=1，平时执行命令`chmod 777 文件名`这就是最高权限了。

  第一个数字7=4+2+1代表着所有者的权限，第二个数字7代表所属组的权限，第三个数字代表其他人的权限。

  常见的权限数字还有644，所有者有读写权限，其他人只有只读权限，755代表其他人有只读和执行权限。

- `chown`：用于修改文件和目录的所有者和所属组。一般用法`chown user 文件`用于修改文件所有者，`chown user:user 文件`修改文件所有者和组，冒号前面是所有者，后面是组。

###### 9.5.3. 常用的压缩命令

- `zip`：压缩zip文件命令，比如`zip test.zip 文件`可以把文件压缩成zip文件，如果压缩目录的话则需添加`-r`选项。

- `unzip`：与zip对应，解压zip文件命令。`unzip xxx.zip`直接解压，还可以通过`-d`选项指定解压目录。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhsKzJfgEjPsW1zqnntxd55JrD6CiaiatfB6cuwZHNAdZvict4ghPRD2vLA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- gzip`：用于压缩.gz后缀文件，gzip命令不能打包目录。需要注意的是直接使用`gzip 文件名`源文件会消失，如果要保留源文件，可以使用`gzip -c 文件名 > xx.gz`，解压缩直接使用`gzip -d xx.gz

- `tar`：tar常用几个选项，`-x`解打包，`-c`打包，`-f`指定压缩包文件名，`-v`显示打包文件过程，一般常用`tar -cvf xx.tar 文件`来打包，解压则使用`tar -xvf xx.tar`。

  Linux的打包和压缩是分开的操作，如果要打包并且压缩的话，按照前面的做法必须先用tar打包，然后再用gzip压缩。当然，还有更好的做法就是`-z`命令，打包并且压缩。

  使用命令`tar -zcvf xx.tar.gz 文件`来打包压缩，使用命令`tar -zxvf xx.tar.gz`来解压缩

----

## 10. 场景设计

#### 10.1. 秒杀场景设计

秒杀这个话题到现在来说已经是一个老生常谈的话题了，不过因为又临近一年一度的双11，而且发现前段时间无论是阿里还是腾讯一些大厂其实还是在频繁的问到这个场景题，所以还是准备拿出来说说。

秒杀从规模上来说可以分为大秒和小秒。大秒指的是比如双11这种特定的节日，商品规模超大、价格超低、流量超大的这种类型活动，小秒一般指的是商家自己配置的一些时段类型的活动，由商家自己指定时间上架。从形式来说还可以分为单时段秒杀和多时段秒杀。但是在这个场景里，一般就是指的单时段大型秒杀。

秒杀设计要面对的压力和难度有几点：

1. 怎么保证超高的流量和并发下系统的稳定性？如果峰值的QPS达到几十万，面对巨大的流量的压力系统怎么设计保证不被打崩？
2. 怎么保证数据最终一致性？比如库存不能超卖，超卖了那亏本的要么就是商家要么就是平台，用户反正不背这个锅，超卖了就今年325预订。

当然，涉及到这种大型的活动，还需要考虑到数据统计分析，总不能活动做完了，效果不知道怎么样。

**系统架构**

假设今年的双11预估峰值QPS将会有50万(我随便扯的)，而根据我们平时的经验单机8C8G的机器可以达到1000左右的QPS，那么从理论上来说我们只要500台机器就可以抗住了，就有钱任性不行？这么设计的话只能出门右转不送了。

**流量过滤**

本质上，参与秒杀的用户很多，但是商品的数量是有限的，真正能抢到的用户并不多，那么第一步就是要过滤掉大部分无效的流量。

1. 活动开始前前端页面的Button置灰，防止活动未开始无效的点击产生流量
2. 前端添加验证码或者答题，防止瞬间产生超高的流量，可以很好的起到错峰的效果，现在的验证码花样繁多，题库有的还要做个小学题，而且题库更新频繁，想暴力破解怕是很难。当然我知道的还有一种人工打码的方式，不过这个也是需要时间的，不像机器无限刷你的接口。
3. 活动校验，既然是活动，那么活动的参与用户，参加条件，用户白名单之类的要首先做一层校验拦截，还有其他的比如用户终端、IP地址、参与活动次数、黑名单用户的校验。比如活动主要针对APP端的用户校验，那么根据参数其他端的用户将被拦截，针对IP、mac地址、设备ID和用户ID可以对用户参与活动的次数做校验，黑名单根据平时的活动经验拦截掉一部分羊毛党等异常用户。
4. 非法请求拦截，做了以上拦截如果还有用户能绕过限制，那不得不说太牛X了。比如双11零点开始还做了答题限制，那么正常人怎么也需要1秒的时间来答题吧，就算单身30年手速我想也不能超过0.5秒了，那么针对刚好0点或者在0.5秒以内的请求就可以完全拦截掉。
5. 限流，假设秒杀10000件商品，我们有10台服务器，单机的QPS在1000，那么理论上1秒就可以抢完，针对微服务就可以做限流配置，避免后续无效的流量打到数据库造成不必要的压力。针对限流还有另外一种栅栏方式限流，这是一种纯靠运气的限流方式，就是在系统约定的请求开始的时间内随机偏移一段时间，针对每个请求的偏移量不同，如果在偏移时间之内就会被拦截，反之通过。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUliapRxGg2WNiciacicz1h72sfRSo37G91OA0AxKJCCiccGtvaBcfPl0mWYmetaUfxuMHGKdHVBL8W6crg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

**性能优化**

做完无效流量的过滤，那么可能你的无效请求已经过滤掉了90%，剩下的有效流量会大大的降低系统的压力。之后就是需要针对系统的性能做出优化了。

1. 页面静态化，参与秒杀活动的商品一般都是已知的，可以针对活动页面做静态化处理，缓存到CDN。假设我们一个页面300K大小，1千万用户的流量是多少？这些请求要请求后端服务器、数据库，压力可想而知，缓存到CDN用户请求不经过服务器，大大减小了服务器的压力。
2. 活动预热，针对活动的活动库存可以独立出来，不和普通的商品库存共享服务，活动库存活动开始前提前加载到redis，查询全部走缓存，最后扣减库存再视情况而定。
3. 独立部署，资源充足的情况下可以考虑针对秒杀活动单独部署一套环境，这套环境中可以剥离一些可能无用的逻辑，比如不用考虑使用优惠券、红包、下单后赠送积分的一些场景，或者这些场景可以活动结束后异步的统一发放。这只是一个举例，实际上单独针对秒杀活动的话你肯定有很多无用的业务代码是可以剥离的，这样可以提高不少性能。

经过这两步之后，最终我们的流量应该是呈漏斗状。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUliapRxGg2WNiciacicz1h72sfRJA3ib69FS9OvfforpzZtWU2DWmSlGCiaVc3c9eurFBibEMU6fUbSeufpQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

**超卖**

秒杀除开高并发高流量下的服务稳定性之外，剩下的核心大概就是怎么保证库存不超卖了，也可以说要保证的是最终一致性。一般来说，针对下单和库存有两种方式:

1. 下单即扣库存，这是最常规的大部分的做法。但是可能在活动中会碰到第二点说到的情况。
2. 支付完成扣库存，这种设计我碰到过就是酒店行业，廉价房放出来之后被黄牛下单抢占库存导致正常用户无法下单，然后黄牛可以用稍高的价格再售卖给用户从中牟利，所以会有在一些活动的时候采取支付成功后才占用库存的做法。**不过这种方式实现起来比较复杂，可能造成大量的无效订单，在秒杀的场景中不太适用**。

针对秒杀建议选择下单扣库存的方式，实现相对简单而且是常规做法。

**方案**

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUliapRxGg2WNiciacicz1h72sfRwrwSKwg5bia2tHY45C1UKgRJ2qxUnVEFiaY0rASibNLQwHqLWuoOVObXA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

1. 首先查询redis缓存库存是否充足
2. 先扣库存再落订单数据，可以防止订单生成了没有库存的超卖问题
3. 扣库存的时候先扣数据库库存，再扣减redis库存，保证在同一个事务里，无论两者哪一个发生了异常都会回滚。有一个问题是可能redis扣成功了由于网络问题返回失败，事务回滚，导致数据库和缓存不一致，这样实际少卖了，可以放到下轮秒杀去。

这种做法能一定程度上解决问题，但是也有可能会有其他问题。比如当大量请求落在同一条库存记录上去做update时，行锁导致大量的锁竞争会使得数据库的tps急剧下降，性能无法满足要求。

另外一种做法就是排队，在服务层进行排队，针对同一个商品ID的也就是数据库是一条库存记录的做一个内存队列，串行化去扣减库存，可以一定程度上缓解数据库的并发压力。

**质量保障**

为了保证系统的稳定性，防止你的系统被秒杀，一些质量监控就不得不做。

1. 熔断限流降级，老生常谈，根据压测情况进行限流，可以使用sentinel或者hystrix。另外前端后端都该有降级开关。
2. 监控，该上的都上，QPS监控、容器监控、CPU、缓存、IO监控等等。
3. 演练，大型秒杀事前演练少不了，不能冒冒失失的就上了吧。
4. 核对、预案，事后库存订单 金额、数量核对，是否发生超卖了?金额是否正常？都是必须的。预案可以在紧急情况下进行降级。

**数据统计**

活动做完了，数据该怎么统计？

1. 前端埋点
2. 数据大盘，通过后台服务的打点配合监控系统可以通过大盘直观的看到一些活动的监控和数据
3. 离线数据分析，事后活动的数据可以同步到离线数仓做进一步的分析统计

**总结**

总的来说，面对巨量的流量我们的方式就是首先通过各种条件先筛选掉无效流量，进行流量错峰，然后再对现有的系统性能做出优化，比如页面静态化，库存商品预热，也可以通过独立部署的方式和其他的环境做隔离，最后还要解决高并发下缓存一致性、库存不能超卖的问题，防止大量的并发打爆你的数据库。

一个完整的活动从前端到后端是一个完整的链路，中间有事前的演练工作，事后的数据分析等都是必不可少的环节。

#### 10.2. 面对千万级、亿级流量如何处理？

###### 10.2.1. 微服务架构演化

在互联网早期的时候，单体架构就足以支撑起日常的业务需求，大家的所有业务服务都在一个项目里，部署在一台物理机器上。所有的业务包括你的交易系统、会员信息、库存、商品等等都夹杂在一起，当流量一旦起来之后，单体架构的问题就暴露出来了，机器挂了所有的业务全部无法使用了。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kk0ialF0DVYbtzN2mqZPMwHIq0h6YiaKegLJWGoO96QM1hlicibxM67D1aSw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

于是，集群架构的架构开始出现，单机无法抗住的压力，最简单的办法就是水平拓展横向扩容了，这样，通过负载均衡把压力流量分摊到不同的机器上，暂时是解决了单点导致服务不可用的问题。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkcsLoebo42vcUWFAalAMmDINrf7AW0aiaDe74gCOyF6eSsZd8DtbVasA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

但是随着业务的发展，在一个项目里维护所有的业务场景使开发和代码维护变得越来越困难，一个简单的需求改动都需要发布整个服务，代码的合并冲突也会变得越来越频繁，同时线上故障出现的可能性越大。微服务的架构模式就诞生了。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkUxmEr8iasnsfBicbNCSkEIpHr8Ep2yCwvLic6uhSeRR3aceVicUIeXF8GA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

把每个独立的业务拆分开独立部署，开发和维护的成本降低，集群能承受的压力也提高了，再也不会出现一个小小的改动点需要牵一发而动全身了。

以上的点从高并发的角度而言，似乎都可以归类为通过服务拆分和集群物理机器的扩展提高了整体的系统抗压能力，那么，随之拆分而带来的问题也就是高并发系统需要解决的问题。

###### 10.2.2. 使用RPC框架

微服务化的拆分带来的好处和便利性是显而易见的，但是与此同时各个微服务之间的通信就需要考虑了。传统HTTP的通信方式对性能是极大的浪费，这时候就需要引入诸如Dubbo类的RPC框架，基于TCP长连接的方式提高整个集群通信的效率。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkPRsicIDaiaLgFzlL3DSxcwTSzTgffDOCvpuIuvw0VvXs0P41BuUI4L2Q/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

我们假设原来来自客户端的QPS是9000的话，那么通过负载均衡策略分散到每台机器就是3000，而HTTP改为RPC之后接口的耗时缩短了，单机和整体的QPS就提升了。而RPC框架本身一般都自带负载均衡、熔断降级的机制，可以更好的维护整个系统的高可用性。

###### 10.2.3. 引入消息队列

对于MQ的作用大家都应该很了解了，削峰填谷、解耦。依赖消息队列，同步转异步的方式，可以降低微服务之间的耦合。

对于一些不需要同步执行的接口，可以通过引入消息队列的方式异步执行以提高接口响应时间。在交易完成之后需要扣库存，然后可能需要给会员发放积分，本质上，发积分的动作应该属于履约服务，对实时性的要求也不高，我们只要保证最终一致性也就是能履约成功就行了。对于这种同类性质的请求就可以走MQ异步，也就提高了系统抗压能力了。**但是要考虑保证消息可靠性和最终一致性**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkFWU0aHOicpRW060Dia8mcMrKmkmZn55GsdYzHNS3xVDRhMopSZAjiaRIA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

对于整个系统而言，最终所有的流量的查询和写入都落在数据库上，数据库是支撑系统高并发能力的核心。怎么降低数据库的压力，提升数据库的性能是支撑高并发的基石。主要的方式就是通过读写分离和分库分表来解决这个问题。

对于整个系统而言，流量应该是一个漏斗的形式。比如我们的日活用户DAU有20万，实际可能每天来到提单页的用户只有3万QPS，最终转化到下单支付成功的QPS只有1万。那么对于系统来说读是大于写的，这时候可以通过读写分离的方式来降低数据库的压力。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkjJm1HxOHS75FLwFmNAXmNqhkwbCeBcUok16Kmr4a4M9rXF93sN1IHQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

读写分离也就相当于数据库集群的方式降低了单节点的压力。而面对数据的急剧增长，原来的单库单表的存储方式已经无法支撑整个业务的发展，这时候就需要对数据库进行分库分表了。针对微服务而言垂直的分库本身已经是做过的，剩下大部分都是分表的方案了。**需要考虑水平分表及分表后id唯一性，以及如何进行主从同步的问题**

###### 10.2.4. 引入缓存

缓存作为高性能的代表，在某些特殊业务可能承担90%以上的热点流量。对于一些活动比如秒杀这种并发QPS可能几十万的场景，引入缓存事先预热可以大幅降低对数据库的压力，10万的QPS对于单机的数据库来说可能就挂了，但是对于如redis这样的缓存来说就完全不是问题。**引入缓存之后就还要考虑缓存击穿、雪崩、热点一系列的问题**

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkeOicPzVFSOSE8eeVYOhBkyBO6HgibpicKt4Wjp3XMW4Ribe9tJK8C1Dibsw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" style="zoom:67%;" />

###### 10.2.5. 系统稳定性

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkwUOehXezU8lZVvC8b9bicpSrymMbJ3niccYoknhboeMoA6AmxkxVRDdA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"  />

**熔断**

比如营销服务挂了或者接口大量超时的异常情况，不能影响下单的主链路，涉及到积分的扣减一些操作可以在事后做补救。

**限流**

对突发如大促秒杀类的高并发，如果一些接口不做限流处理，可能直接就把服务打挂了，针对每个接口的压测性能的评估做出合适的限流尤为重要。

**降级**

熔断之后实际上可以说就是降级的一种，以熔断的举例来说营销接口熔断之后降级方案就是短时间内不再调用营销的服务，等到营销恢复之后再调用。

**预案**

一般来说，就算是有统一配置中心，在业务的高峰期也是不允许做出任何的变更的，但是通过配置合理的预案可以在紧急的时候做一些修改。

**核对**

针对各种分布式系统产生的分布式事务一致性或者受到攻击导致的数据异常，非常需要核对平台来做最后的兜底的数据验证。比如下游支付系统和订单系统的金额做核对是否正确，如果收到中间人攻击落库的数据是否保证正确性。

----

## 11. 项目介绍

#### 11.1. 介绍项目整体架构

THC是基于 Spring Cloud 搭建的一个微服务系统。

服务层采用 Eureka 来实现服务注册和发现的功能，采用 Feign 做的系统间调用，使用 Ribbon 做的负载均衡，使用 Hystrix 做的系统保护，并采用 sky walking 作为链路追踪，以方便定位问题和系统优化。

数据层采用 mysql 做为数据库，redis做缓存，并引入消息队列来实现系统间的解耦。

<img src="/Users/fangyunzhe/Library/Application Support/typora-user-images/image-20201227113749367.png" alt="image-20201227113749367" style="zoom:67%;" />

#### 11.2. 介绍项目主要功能

THC 为医疗机构提供整体解决方案，从业务上整体分为三个大的功能模块：诊疗模块、供应链模块、财务模块，每个模块都由不同的子系统构成

**诊疗模块**：主要管人，包括 ARRANGE 排班挂号系统、 CPOE 电子处方系统、ADT 住院流程管理、PHR电子病历系统等。

**供应链模块**：主要管物，包括库房管理、发药流程管理等系统

**财务模块**：主要管钱，包括 RCM 收入周期管理、INSURANCE 保险管理、MARKET 营销管理、PRICE-MANGAGER 价格管控以及支付系统等。

另外，基于 THC 搭建了互联网医院，将院内服务延伸至院外，提供在线预约、问诊等功能。